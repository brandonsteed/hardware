{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning CNN Model - Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 3s 961us/step - loss: 1.3031 - acc: 0.4461 - val_loss: 1.0175 - val_acc: 0.5908\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 1s 207us/step - loss: 1.0002 - acc: 0.5858 - val_loss: 1.4297 - val_acc: 0.5353\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 1s 209us/step - loss: 0.8462 - acc: 0.6639 - val_loss: 0.6558 - val_acc: 0.7468\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 1s 204us/step - loss: 0.6928 - acc: 0.7393 - val_loss: 0.5081 - val_acc: 0.8344\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 1s 192us/step - loss: 0.6038 - acc: 0.7744 - val_loss: 1.5001 - val_acc: 0.5769\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 1s 198us/step - loss: 0.5246 - acc: 0.8117 - val_loss: 1.1025 - val_acc: 0.6485\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.4648 - acc: 0.8366 - val_loss: 0.3645 - val_acc: 0.8622\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 1s 190us/step - loss: 0.4054 - acc: 0.8540 - val_loss: 0.3425 - val_acc: 0.8793\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.3689 - acc: 0.8663 - val_loss: 0.4630 - val_acc: 0.8344\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 1s 190us/step - loss: 0.3088 - acc: 0.8907 - val_loss: 0.2708 - val_acc: 0.9060\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 1s 196us/step - loss: 0.2852 - acc: 0.8988 - val_loss: 0.4160 - val_acc: 0.8729\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 1s 190us/step - loss: 0.2536 - acc: 0.9111 - val_loss: 0.1952 - val_acc: 0.9412\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 1s 191us/step - loss: 0.2268 - acc: 0.9165 - val_loss: 0.1987 - val_acc: 0.9306\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 1s 185us/step - loss: 0.2120 - acc: 0.9237 - val_loss: 0.3384 - val_acc: 0.8835\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 1s 185us/step - loss: 0.1931 - acc: 0.9333 - val_loss: 0.1672 - val_acc: 0.9466\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 1s 186us/step - loss: 0.1677 - acc: 0.9444 - val_loss: 0.1764 - val_acc: 0.9402\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 1s 187us/step - loss: 0.1620 - acc: 0.9426 - val_loss: 0.1693 - val_acc: 0.9498\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 1s 187us/step - loss: 0.1596 - acc: 0.9462 - val_loss: 0.1746 - val_acc: 0.9402\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.1418 - acc: 0.9522 - val_loss: 0.2822 - val_acc: 0.8996\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.1219 - acc: 0.9588 - val_loss: 0.1297 - val_acc: 0.9615\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 1s 194us/step - loss: 0.1193 - acc: 0.9549 - val_loss: 0.1717 - val_acc: 0.9380\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 1s 192us/step - loss: 0.1186 - acc: 0.9619 - val_loss: 0.1012 - val_acc: 0.9679\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 1s 190us/step - loss: 0.1057 - acc: 0.9649 - val_loss: 0.1109 - val_acc: 0.9647\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 1s 185us/step - loss: 0.1002 - acc: 0.9673 - val_loss: 0.1175 - val_acc: 0.9583\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 1s 189us/step - loss: 0.0845 - acc: 0.9709 - val_loss: 0.1049 - val_acc: 0.9573\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.0866 - acc: 0.9709 - val_loss: 0.0939 - val_acc: 0.9701\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 1s 195us/step - loss: 0.0844 - acc: 0.9736 - val_loss: 0.0993 - val_acc: 0.9669\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 1s 192us/step - loss: 0.0880 - acc: 0.9682 - val_loss: 0.1156 - val_acc: 0.9594\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 1s 198us/step - loss: 0.0747 - acc: 0.9772 - val_loss: 0.1017 - val_acc: 0.9658\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 1s 191us/step - loss: 0.0681 - acc: 0.9766 - val_loss: 0.1172 - val_acc: 0.9562\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.0740 - acc: 0.9745 - val_loss: 0.1128 - val_acc: 0.9626\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 1s 192us/step - loss: 0.0597 - acc: 0.9832 - val_loss: 0.0826 - val_acc: 0.9754\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 1s 195us/step - loss: 0.0612 - acc: 0.9823 - val_loss: 0.0799 - val_acc: 0.9797\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 1s 196us/step - loss: 0.0739 - acc: 0.9754 - val_loss: 0.0941 - val_acc: 0.9744\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 1s 196us/step - loss: 0.0604 - acc: 0.9802 - val_loss: 0.0894 - val_acc: 0.9722\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 1s 191us/step - loss: 0.0539 - acc: 0.9814 - val_loss: 0.2134 - val_acc: 0.9220\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 1s 200us/step - loss: 0.0487 - acc: 0.9841 - val_loss: 0.0924 - val_acc: 0.9712\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.0330 - acc: 0.9913 - val_loss: 0.0919 - val_acc: 0.9701\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 1s 187us/step - loss: 0.0493 - acc: 0.9850 - val_loss: 0.0799 - val_acc: 0.9733\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 1s 187us/step - loss: 0.0351 - acc: 0.9889 - val_loss: 0.0856 - val_acc: 0.9754\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 1s 189us/step - loss: 0.0504 - acc: 0.9853 - val_loss: 0.1020 - val_acc: 0.9690\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 1s 190us/step - loss: 0.0382 - acc: 0.9892 - val_loss: 0.0776 - val_acc: 0.9786\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 1s 191us/step - loss: 0.0348 - acc: 0.9886 - val_loss: 0.0755 - val_acc: 0.9786\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.0496 - acc: 0.9835 - val_loss: 0.0757 - val_acc: 0.9744\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.0459 - acc: 0.9835 - val_loss: 0.0881 - val_acc: 0.9712\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 1s 193us/step - loss: 0.0360 - acc: 0.9880 - val_loss: 0.0799 - val_acc: 0.9754\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 1s 195us/step - loss: 0.0387 - acc: 0.9883 - val_loss: 0.0854 - val_acc: 0.9722\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 1s 191us/step - loss: 0.0272 - acc: 0.9895 - val_loss: 0.0904 - val_acc: 0.9786\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 1s 194us/step - loss: 0.0387 - acc: 0.9880 - val_loss: 0.0865 - val_acc: 0.9776\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 1s 194us/step - loss: 0.0243 - acc: 0.9919 - val_loss: 0.0911 - val_acc: 0.9754\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 287us/step - loss: 1.4003 - acc: 0.4112 - val_loss: 1.9541 - val_acc: 0.2350\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 1.1316 - acc: 0.5416 - val_loss: 0.9982 - val_acc: 0.6485\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.9516 - acc: 0.6248 - val_loss: 0.7691 - val_acc: 0.6944\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: 0.8272 - acc: 0.6897 - val_loss: 2.0697 - val_acc: 0.4370\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.7575 - acc: 0.7221 - val_loss: 1.4681 - val_acc: 0.5214\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.6405 - acc: 0.7708 - val_loss: 1.0144 - val_acc: 0.5459\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.5683 - acc: 0.7942 - val_loss: 0.5863 - val_acc: 0.8045\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.5112 - acc: 0.8228 - val_loss: 2.8108 - val_acc: 0.5053\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.4867 - acc: 0.8390 - val_loss: 1.1595 - val_acc: 0.5716\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.4141 - acc: 0.8540 - val_loss: 0.3614 - val_acc: 0.8857\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.3844 - acc: 0.8738 - val_loss: 0.3922 - val_acc: 0.8611\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.3533 - acc: 0.8798 - val_loss: 0.2971 - val_acc: 0.9103\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.3276 - acc: 0.8792 - val_loss: 0.2775 - val_acc: 0.9092\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.3026 - acc: 0.8967 - val_loss: 0.2559 - val_acc: 0.9220\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.2839 - acc: 0.8991 - val_loss: 0.2186 - val_acc: 0.9316\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.2746 - acc: 0.9054 - val_loss: 0.2018 - val_acc: 0.9434\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.2428 - acc: 0.9228 - val_loss: 0.4863 - val_acc: 0.8216\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.2173 - acc: 0.9279 - val_loss: 0.1938 - val_acc: 0.9423\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.2039 - acc: 0.9303 - val_loss: 0.1789 - val_acc: 0.9444\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1958 - acc: 0.9327 - val_loss: 0.1820 - val_acc: 0.9519\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1696 - acc: 0.9465 - val_loss: 0.1650 - val_acc: 0.9509\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1826 - acc: 0.9393 - val_loss: 1.0306 - val_acc: 0.6891\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1582 - acc: 0.9504 - val_loss: 0.1734 - val_acc: 0.9370\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1301 - acc: 0.9576 - val_loss: 0.1332 - val_acc: 0.9519\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.1186 - acc: 0.9603 - val_loss: 0.1349 - val_acc: 0.9573\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.1272 - acc: 0.9564 - val_loss: 2.4067 - val_acc: 0.5855\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1570 - acc: 0.9597 - val_loss: 0.3072 - val_acc: 0.8921\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.1000 - acc: 0.9694 - val_loss: 0.0974 - val_acc: 0.9626\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.0994 - acc: 0.9670 - val_loss: 0.1355 - val_acc: 0.9562\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1132 - acc: 0.9622 - val_loss: 0.2061 - val_acc: 0.9284\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0824 - acc: 0.9742 - val_loss: 0.0967 - val_acc: 0.9647\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.0818 - acc: 0.9721 - val_loss: 0.0987 - val_acc: 0.9690\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.0781 - acc: 0.9718 - val_loss: 0.0928 - val_acc: 0.9679\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1159 - acc: 0.9619 - val_loss: 0.1302 - val_acc: 0.9562\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0634 - acc: 0.9811 - val_loss: 0.1164 - val_acc: 0.9626\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.0743 - acc: 0.9769 - val_loss: 0.1063 - val_acc: 0.9712\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0631 - acc: 0.9805 - val_loss: 0.0786 - val_acc: 0.9754\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0719 - acc: 0.9763 - val_loss: 0.1504 - val_acc: 0.9530\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0616 - acc: 0.9820 - val_loss: 0.0923 - val_acc: 0.9712\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0575 - acc: 0.9832 - val_loss: 0.1091 - val_acc: 0.9615\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0820 - acc: 0.9721 - val_loss: 0.0872 - val_acc: 0.9744\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0398 - acc: 0.9892 - val_loss: 0.0940 - val_acc: 0.9722\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0577 - acc: 0.9793 - val_loss: 0.0812 - val_acc: 0.9722\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.0574 - acc: 0.9826 - val_loss: 0.0868 - val_acc: 0.9701\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0474 - acc: 0.9856 - val_loss: 0.0856 - val_acc: 0.9679\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0442 - acc: 0.9871 - val_loss: 0.1655 - val_acc: 0.9541\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0429 - acc: 0.9874 - val_loss: 0.6698 - val_acc: 0.8002\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0484 - acc: 0.9859 - val_loss: 0.1094 - val_acc: 0.9679\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0364 - acc: 0.9892 - val_loss: 0.0770 - val_acc: 0.9786\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.0453 - acc: 0.9853 - val_loss: 0.0702 - val_acc: 0.9765\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 288us/step - loss: 1.4682 - acc: 0.3806 - val_loss: 2.6220 - val_acc: 0.3013\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 1.2885 - acc: 0.4779 - val_loss: 1.2658 - val_acc: 0.4274\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 1.1120 - acc: 0.5440 - val_loss: 1.1829 - val_acc: 0.5374\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 1.0240 - acc: 0.5888 - val_loss: 1.3312 - val_acc: 0.5545\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.9973 - acc: 0.6194 - val_loss: 1.2054 - val_acc: 0.4530\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.8774 - acc: 0.6621 - val_loss: 1.6499 - val_acc: 0.4925\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.8649 - acc: 0.6750 - val_loss: 1.0278 - val_acc: 0.5075\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 70us/step - loss: 0.7557 - acc: 0.7191 - val_loss: 0.6365 - val_acc: 0.7788\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.6868 - acc: 0.7447 - val_loss: 0.7853 - val_acc: 0.7105\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.6731 - acc: 0.7441 - val_loss: 0.7831 - val_acc: 0.7212\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.6237 - acc: 0.7648 - val_loss: 0.5341 - val_acc: 0.8098\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.6011 - acc: 0.7822 - val_loss: 1.0290 - val_acc: 0.5897\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.5826 - acc: 0.7804 - val_loss: 0.5003 - val_acc: 0.8184\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.5229 - acc: 0.8093 - val_loss: 0.4195 - val_acc: 0.8547\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.4667 - acc: 0.8306 - val_loss: 0.6505 - val_acc: 0.7382\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.4868 - acc: 0.8222 - val_loss: 0.7864 - val_acc: 0.6645\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.4809 - acc: 0.8270 - val_loss: 1.0520 - val_acc: 0.6346\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.4148 - acc: 0.8549 - val_loss: 0.3623 - val_acc: 0.8889\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.3661 - acc: 0.8681 - val_loss: 0.4426 - val_acc: 0.8451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 78us/step - loss: 0.4073 - acc: 0.8486 - val_loss: 0.6672 - val_acc: 0.7853\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.3970 - acc: 0.8561 - val_loss: 0.2924 - val_acc: 0.9071\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.3031 - acc: 0.8901 - val_loss: 0.3478 - val_acc: 0.8761\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 75us/step - loss: 0.3166 - acc: 0.8895 - val_loss: 0.2576 - val_acc: 0.9113\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.2876 - acc: 0.8943 - val_loss: 0.3777 - val_acc: 0.8771\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 75us/step - loss: 0.2694 - acc: 0.9111 - val_loss: 0.2114 - val_acc: 0.9199\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.2606 - acc: 0.9090 - val_loss: 0.4135 - val_acc: 0.8526\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.2388 - acc: 0.9165 - val_loss: 0.2397 - val_acc: 0.9274\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.2578 - acc: 0.9153 - val_loss: 0.5595 - val_acc: 0.8066\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.2608 - acc: 0.9114 - val_loss: 0.1743 - val_acc: 0.9434\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.1888 - acc: 0.9354 - val_loss: 0.2436 - val_acc: 0.9209\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.1884 - acc: 0.9348 - val_loss: 0.2020 - val_acc: 0.9316\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 75us/step - loss: 0.1745 - acc: 0.9432 - val_loss: 0.1488 - val_acc: 0.9487\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1871 - acc: 0.9327 - val_loss: 0.8576 - val_acc: 0.6998\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.2380 - acc: 0.9213 - val_loss: 0.8573 - val_acc: 0.6848\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.2380 - acc: 0.9228 - val_loss: 0.1364 - val_acc: 0.9562\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1248 - acc: 0.9600 - val_loss: 0.1321 - val_acc: 0.9573\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.1327 - acc: 0.9594 - val_loss: 0.1260 - val_acc: 0.9605\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1460 - acc: 0.9516 - val_loss: 0.1851 - val_acc: 0.9391\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 73us/step - loss: 0.1308 - acc: 0.9570 - val_loss: 0.1942 - val_acc: 0.9348\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1673 - acc: 0.9429 - val_loss: 0.1253 - val_acc: 0.9562\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 74us/step - loss: 0.1396 - acc: 0.9510 - val_loss: 0.1216 - val_acc: 0.9658\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1060 - acc: 0.9634 - val_loss: 0.1255 - val_acc: 0.9637\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1258 - acc: 0.9619 - val_loss: 0.0969 - val_acc: 0.9690\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 75us/step - loss: 0.1278 - acc: 0.9582 - val_loss: 0.1068 - val_acc: 0.9647\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.1003 - acc: 0.9676 - val_loss: 0.1581 - val_acc: 0.9391\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 75us/step - loss: 0.0988 - acc: 0.9664 - val_loss: 0.0881 - val_acc: 0.9679\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 72us/step - loss: 0.1130 - acc: 0.9612 - val_loss: 0.6310 - val_acc: 0.8365\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 71us/step - loss: 0.1178 - acc: 0.9640 - val_loss: 0.0883 - val_acc: 0.9679\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 75us/step - loss: 0.0768 - acc: 0.9781 - val_loss: 0.1301 - val_acc: 0.9594\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 70us/step - loss: 0.0819 - acc: 0.9745 - val_loss: 0.0814 - val_acc: 0.9754\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 259us/step - loss: 1.5461 - acc: 0.3019 - val_loss: 1.6379 - val_acc: 0.2682\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 1.4181 - acc: 0.4178 - val_loss: 1.3638 - val_acc: 0.4327\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 1.3219 - acc: 0.4626 - val_loss: 1.2800 - val_acc: 0.5171\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 1.2325 - acc: 0.4857 - val_loss: 1.3604 - val_acc: 0.3323\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 1.1318 - acc: 0.5266 - val_loss: 1.6974 - val_acc: 0.3558\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 1.1242 - acc: 0.5626 - val_loss: 1.2717 - val_acc: 0.5096\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 1.0506 - acc: 0.5843 - val_loss: 0.9746 - val_acc: 0.5705\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.9933 - acc: 0.5957 - val_loss: 1.6267 - val_acc: 0.3985\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 1.0234 - acc: 0.6002 - val_loss: 0.8829 - val_acc: 0.6442\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.9145 - acc: 0.6425 - val_loss: 1.2861 - val_acc: 0.4850\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 57us/step - loss: 0.8812 - acc: 0.6630 - val_loss: 1.8628 - val_acc: 0.4071\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.9536 - acc: 0.6476 - val_loss: 0.8078 - val_acc: 0.6838\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.7794 - acc: 0.7089 - val_loss: 0.7807 - val_acc: 0.7019\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.7605 - acc: 0.7185 - val_loss: 0.7067 - val_acc: 0.7447\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.7247 - acc: 0.7318 - val_loss: 1.3371 - val_acc: 0.5214\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.7686 - acc: 0.7263 - val_loss: 0.7388 - val_acc: 0.7126\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 51us/step - loss: 0.6809 - acc: 0.7474 - val_loss: 0.9121 - val_acc: 0.5620\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.6885 - acc: 0.7450 - val_loss: 0.7198 - val_acc: 0.7190\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.6463 - acc: 0.7663 - val_loss: 3.3507 - val_acc: 0.4412\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.8392 - acc: 0.7363 - val_loss: 0.5326 - val_acc: 0.8397\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.5759 - acc: 0.7954 - val_loss: 0.5964 - val_acc: 0.7906\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.5693 - acc: 0.7966 - val_loss: 1.0097 - val_acc: 0.6079\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 0.6033 - acc: 0.7843 - val_loss: 0.7046 - val_acc: 0.7361\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.5427 - acc: 0.8035 - val_loss: 0.5902 - val_acc: 0.7724\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 0.5300 - acc: 0.8108 - val_loss: 0.4934 - val_acc: 0.8451\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.4970 - acc: 0.8258 - val_loss: 0.5543 - val_acc: 0.8002\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.5083 - acc: 0.8231 - val_loss: 0.4539 - val_acc: 0.8536\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 0.4732 - acc: 0.8333 - val_loss: 0.4024 - val_acc: 0.8686\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.4507 - acc: 0.8414 - val_loss: 0.3807 - val_acc: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.4293 - acc: 0.8468 - val_loss: 0.4209 - val_acc: 0.8526\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.4449 - acc: 0.8453 - val_loss: 0.4997 - val_acc: 0.7949\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.4189 - acc: 0.8480 - val_loss: 0.5121 - val_acc: 0.8077\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.4398 - acc: 0.8405 - val_loss: 0.8419 - val_acc: 0.7297\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.4967 - acc: 0.8312 - val_loss: 0.3221 - val_acc: 0.9017\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.4115 - acc: 0.8519 - val_loss: 0.5025 - val_acc: 0.8291\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.3841 - acc: 0.8663 - val_loss: 0.8608 - val_acc: 0.6143\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.4464 - acc: 0.8498 - val_loss: 0.5195 - val_acc: 0.7949\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.3706 - acc: 0.8720 - val_loss: 0.4217 - val_acc: 0.8429\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.3257 - acc: 0.8898 - val_loss: 0.4224 - val_acc: 0.8729\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.3249 - acc: 0.8871 - val_loss: 0.4303 - val_acc: 0.8237\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.3303 - acc: 0.8828 - val_loss: 0.7747 - val_acc: 0.7585\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 0.3615 - acc: 0.8822 - val_loss: 0.3113 - val_acc: 0.8932\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 56us/step - loss: 0.2842 - acc: 0.9057 - val_loss: 0.2772 - val_acc: 0.9071\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.2656 - acc: 0.9087 - val_loss: 0.2459 - val_acc: 0.9209\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.2694 - acc: 0.9105 - val_loss: 0.2299 - val_acc: 0.9316\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 54us/step - loss: 0.2543 - acc: 0.9168 - val_loss: 1.9004 - val_acc: 0.5919\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.4738 - acc: 0.8633 - val_loss: 0.3641 - val_acc: 0.8793\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 53us/step - loss: 0.2483 - acc: 0.9171 - val_loss: 0.2132 - val_acc: 0.9359\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 55us/step - loss: 0.2315 - acc: 0.9201 - val_loss: 0.2162 - val_acc: 0.9380\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 52us/step - loss: 0.2314 - acc: 0.9279 - val_loss: 0.2252 - val_acc: 0.9295\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in [32, 64, 128, 256]:\n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                    optimizer=keras.optimizers.Adadelta(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=i,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['batch_size', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.975427</td>\n",
       "      <td>0.971185</td>\n",
       "      <td>35.650254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.976496</td>\n",
       "      <td>0.972252</td>\n",
       "      <td>20.248005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.975427</td>\n",
       "      <td>0.969050</td>\n",
       "      <td>13.804427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>0.949234</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.910352</td>\n",
       "      <td>10.686313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  training_accuracy  validation_accuracy  test_accuracy  \\\n",
       "0          32           0.999700             0.975427       0.971185   \n",
       "1          64           0.999700             0.976496       0.972252   \n",
       "2         128           0.996395             0.975427       0.969050   \n",
       "3         256           0.949234             0.929487       0.910352   \n",
       "\n",
       "    run_time  \n",
       "0  35.650254  \n",
       "1  20.248005  \n",
       "2  13.804427  \n",
       "3  10.686313  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Dense Layer Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 324us/step - loss: 1.4292 - acc: 0.3689 - val_loss: 1.2733 - val_acc: 0.3846\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 1.2130 - acc: 0.4854 - val_loss: 1.0853 - val_acc: 0.5192\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 1.0726 - acc: 0.5530 - val_loss: 1.0981 - val_acc: 0.4840\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.9859 - acc: 0.5900 - val_loss: 1.4219 - val_acc: 0.5085\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.9303 - acc: 0.6254 - val_loss: 0.7263 - val_acc: 0.7724\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.7965 - acc: 0.6726 - val_loss: 2.3308 - val_acc: 0.4744\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.7922 - acc: 0.6924 - val_loss: 2.2301 - val_acc: 0.5096\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.7062 - acc: 0.7284 - val_loss: 0.6937 - val_acc: 0.6891\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.6531 - acc: 0.7408 - val_loss: 0.6209 - val_acc: 0.7767\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.6137 - acc: 0.7558 - val_loss: 0.6484 - val_acc: 0.7564\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.5851 - acc: 0.7690 - val_loss: 0.4288 - val_acc: 0.8483\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.5696 - acc: 0.7810 - val_loss: 0.4289 - val_acc: 0.8814\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.5252 - acc: 0.7918 - val_loss: 0.5752 - val_acc: 0.7810\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.5135 - acc: 0.8023 - val_loss: 0.3192 - val_acc: 0.9092\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.4577 - acc: 0.8213 - val_loss: 0.3065 - val_acc: 0.9028\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.4634 - acc: 0.8135 - val_loss: 0.3106 - val_acc: 0.8900\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.4172 - acc: 0.8378 - val_loss: 0.3151 - val_acc: 0.8814\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.4157 - acc: 0.8387 - val_loss: 0.3430 - val_acc: 0.8675\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.4212 - acc: 0.8372 - val_loss: 0.3029 - val_acc: 0.9049\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.3908 - acc: 0.8549 - val_loss: 0.5726 - val_acc: 0.7425\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.3835 - acc: 0.8471 - val_loss: 1.3110 - val_acc: 0.6154\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.3786 - acc: 0.8627 - val_loss: 0.2147 - val_acc: 0.9209\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.3310 - acc: 0.8771 - val_loss: 0.2456 - val_acc: 0.9220\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.3342 - acc: 0.8672 - val_loss: 0.1837 - val_acc: 0.9455\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.3271 - acc: 0.8678 - val_loss: 0.2391 - val_acc: 0.9188\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.3082 - acc: 0.8834 - val_loss: 0.4353 - val_acc: 0.8323\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.3311 - acc: 0.8732 - val_loss: 1.3104 - val_acc: 0.6774\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.3226 - acc: 0.8886 - val_loss: 0.2269 - val_acc: 0.9274\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.2944 - acc: 0.8892 - val_loss: 0.1728 - val_acc: 0.9455\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.2713 - acc: 0.8970 - val_loss: 0.1927 - val_acc: 0.9359\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.2931 - acc: 0.8931 - val_loss: 0.1954 - val_acc: 0.9423\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.2575 - acc: 0.9003 - val_loss: 0.1567 - val_acc: 0.9519\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.2672 - acc: 0.8937 - val_loss: 0.1538 - val_acc: 0.9541\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.2598 - acc: 0.9042 - val_loss: 0.1630 - val_acc: 0.9455\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: 0.2401 - acc: 0.9051 - val_loss: 0.1360 - val_acc: 0.9583\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.2349 - acc: 0.9111 - val_loss: 0.1444 - val_acc: 0.9615\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.2305 - acc: 0.9114 - val_loss: 0.3828 - val_acc: 0.8771\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.2226 - acc: 0.9147 - val_loss: 0.1180 - val_acc: 0.9679\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.2104 - acc: 0.9201 - val_loss: 0.1935 - val_acc: 0.9327\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.2077 - acc: 0.9216 - val_loss: 0.3376 - val_acc: 0.8739\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1946 - acc: 0.9315 - val_loss: 0.3758 - val_acc: 0.8910\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1855 - acc: 0.9294 - val_loss: 0.1137 - val_acc: 0.9669\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.2015 - acc: 0.9237 - val_loss: 0.1125 - val_acc: 0.9669\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1868 - acc: 0.9297 - val_loss: 0.1046 - val_acc: 0.9754\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.1792 - acc: 0.9321 - val_loss: 0.0989 - val_acc: 0.9701\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: 0.2072 - acc: 0.9216 - val_loss: 0.1008 - val_acc: 0.9712\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1598 - acc: 0.9357 - val_loss: 0.2380 - val_acc: 0.9156\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1676 - acc: 0.9393 - val_loss: 0.1620 - val_acc: 0.9444\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1778 - acc: 0.9360 - val_loss: 0.1579 - val_acc: 0.9519\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1675 - acc: 0.9372 - val_loss: 0.1292 - val_acc: 0.9573\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 329us/step - loss: 1.4299 - acc: 0.3881 - val_loss: 1.2631 - val_acc: 0.4701\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 1.1682 - acc: 0.5029 - val_loss: 1.2937 - val_acc: 0.5331\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 1.0305 - acc: 0.5701 - val_loss: 0.8391 - val_acc: 0.6699\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.9221 - acc: 0.6224 - val_loss: 0.7985 - val_acc: 0.6827\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.8285 - acc: 0.6648 - val_loss: 0.6900 - val_acc: 0.7799\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.7290 - acc: 0.7218 - val_loss: 0.5708 - val_acc: 0.7938\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.6710 - acc: 0.7447 - val_loss: 0.6383 - val_acc: 0.7767\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.6550 - acc: 0.7525 - val_loss: 1.3773 - val_acc: 0.5641\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.5906 - acc: 0.7819 - val_loss: 0.7159 - val_acc: 0.7585\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.5228 - acc: 0.8035 - val_loss: 0.4173 - val_acc: 0.8622\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.4827 - acc: 0.8186 - val_loss: 0.3822 - val_acc: 0.8771\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.4725 - acc: 0.8285 - val_loss: 0.3598 - val_acc: 0.8825\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.4327 - acc: 0.8366 - val_loss: 0.5057 - val_acc: 0.8098\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.4179 - acc: 0.8414 - val_loss: 0.3792 - val_acc: 0.8697\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.3773 - acc: 0.8648 - val_loss: 0.2682 - val_acc: 0.9060\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.3824 - acc: 0.8639 - val_loss: 0.2455 - val_acc: 0.9316\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.3421 - acc: 0.8786 - val_loss: 0.2758 - val_acc: 0.9006\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.3309 - acc: 0.8804 - val_loss: 0.3209 - val_acc: 0.8974\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.3005 - acc: 0.8862 - val_loss: 0.1975 - val_acc: 0.9370\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.3202 - acc: 0.8831 - val_loss: 0.2420 - val_acc: 0.9156\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.2624 - acc: 0.9099 - val_loss: 0.2067 - val_acc: 0.9295\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.2816 - acc: 0.9036 - val_loss: 0.1936 - val_acc: 0.9338\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.2317 - acc: 0.9159 - val_loss: 0.2163 - val_acc: 0.9263\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.2493 - acc: 0.9144 - val_loss: 0.2257 - val_acc: 0.9124\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.2096 - acc: 0.9231 - val_loss: 1.7934 - val_acc: 0.6293\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2547 - acc: 0.9216 - val_loss: 0.1478 - val_acc: 0.9551\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.1902 - acc: 0.9339 - val_loss: 0.2513 - val_acc: 0.9231\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1880 - acc: 0.9333 - val_loss: 0.1455 - val_acc: 0.9509\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.2087 - acc: 0.9255 - val_loss: 2.3043 - val_acc: 0.6346\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.2103 - acc: 0.9333 - val_loss: 0.1219 - val_acc: 0.9615\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1615 - acc: 0.9429 - val_loss: 0.2048 - val_acc: 0.9370\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.1691 - acc: 0.9396 - val_loss: 0.4041 - val_acc: 0.8291\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.1648 - acc: 0.9438 - val_loss: 0.1416 - val_acc: 0.9476\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1599 - acc: 0.9459 - val_loss: 0.1195 - val_acc: 0.9637\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1346 - acc: 0.9555 - val_loss: 0.1077 - val_acc: 0.9594\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.1474 - acc: 0.9495 - val_loss: 0.3138 - val_acc: 0.8761\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1470 - acc: 0.9492 - val_loss: 0.0973 - val_acc: 0.9690\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1404 - acc: 0.9555 - val_loss: 0.0920 - val_acc: 0.9679\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1206 - acc: 0.9594 - val_loss: 0.1227 - val_acc: 0.9573\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1353 - acc: 0.9495 - val_loss: 0.0997 - val_acc: 0.9669\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.1362 - acc: 0.9537 - val_loss: 0.0904 - val_acc: 0.9669\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1242 - acc: 0.9555 - val_loss: 0.0847 - val_acc: 0.9744\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1270 - acc: 0.9552 - val_loss: 0.1426 - val_acc: 0.9509\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.1018 - acc: 0.9655 - val_loss: 0.0873 - val_acc: 0.9712\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1223 - acc: 0.9558 - val_loss: 0.3676 - val_acc: 0.8750\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.1651 - acc: 0.9492 - val_loss: 0.0927 - val_acc: 0.9658\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.0901 - acc: 0.9700 - val_loss: 0.0928 - val_acc: 0.9679\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.1032 - acc: 0.9640 - val_loss: 0.2855 - val_acc: 0.8803\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: 0.0867 - acc: 0.9718 - val_loss: 0.0888 - val_acc: 0.9712\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: 0.1067 - acc: 0.9637 - val_loss: 0.0744 - val_acc: 0.9765\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 349us/step - loss: 1.3893 - acc: 0.4187 - val_loss: 1.2526 - val_acc: 0.3600\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 1.1213 - acc: 0.5467 - val_loss: 1.6632 - val_acc: 0.3718\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.9796 - acc: 0.6149 - val_loss: 1.2736 - val_acc: 0.4818\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.8397 - acc: 0.6774 - val_loss: 1.0249 - val_acc: 0.5962\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.7517 - acc: 0.7137 - val_loss: 0.5959 - val_acc: 0.7981\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.6956 - acc: 0.7333 - val_loss: 0.6573 - val_acc: 0.7735\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.5984 - acc: 0.7825 - val_loss: 1.2989 - val_acc: 0.6004\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.5478 - acc: 0.8074 - val_loss: 1.1729 - val_acc: 0.5823\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.4921 - acc: 0.8285 - val_loss: 1.6124 - val_acc: 0.5459\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.4409 - acc: 0.8507 - val_loss: 0.5842 - val_acc: 0.7938\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.3848 - acc: 0.8606 - val_loss: 0.3617 - val_acc: 0.8718\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.3405 - acc: 0.8804 - val_loss: 0.8464 - val_acc: 0.6079\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.3335 - acc: 0.8874 - val_loss: 0.2559 - val_acc: 0.9220\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2809 - acc: 0.9066 - val_loss: 0.2536 - val_acc: 0.9220\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2848 - acc: 0.9066 - val_loss: 0.2244 - val_acc: 0.9274\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2274 - acc: 0.9234 - val_loss: 0.2349 - val_acc: 0.9199\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2365 - acc: 0.9156 - val_loss: 1.5891 - val_acc: 0.6239\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2279 - acc: 0.9294 - val_loss: 0.1631 - val_acc: 0.9519\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.2156 - acc: 0.9264 - val_loss: 0.1719 - val_acc: 0.9487\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1634 - acc: 0.9456 - val_loss: 0.1493 - val_acc: 0.9519\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.1471 - acc: 0.9534 - val_loss: 0.1391 - val_acc: 0.9519\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1781 - acc: 0.9384 - val_loss: 0.2170 - val_acc: 0.9188\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1427 - acc: 0.9622 - val_loss: 0.1333 - val_acc: 0.9637\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.1542 - acc: 0.9447 - val_loss: 0.1592 - val_acc: 0.9509\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.1078 - acc: 0.9673 - val_loss: 0.1221 - val_acc: 0.9615\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1271 - acc: 0.9570 - val_loss: 0.2139 - val_acc: 0.9263\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: 0.1118 - acc: 0.9637 - val_loss: 0.1230 - val_acc: 0.9583\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0906 - acc: 0.9739 - val_loss: 0.1388 - val_acc: 0.9509\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0982 - acc: 0.9676 - val_loss: 0.1152 - val_acc: 0.9647\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0925 - acc: 0.9721 - val_loss: 0.1215 - val_acc: 0.9615\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0934 - acc: 0.9682 - val_loss: 0.1354 - val_acc: 0.9573\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0815 - acc: 0.9742 - val_loss: 0.1067 - val_acc: 0.9712\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0651 - acc: 0.9796 - val_loss: 0.0945 - val_acc: 0.9733\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0721 - acc: 0.9778 - val_loss: 0.2120 - val_acc: 0.9274\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0700 - acc: 0.9811 - val_loss: 0.0861 - val_acc: 0.9712\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0526 - acc: 0.9847 - val_loss: 0.0826 - val_acc: 0.9701\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0598 - acc: 0.9811 - val_loss: 0.0959 - val_acc: 0.9712\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0706 - acc: 0.9766 - val_loss: 0.0788 - val_acc: 0.9744\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0615 - acc: 0.9796 - val_loss: 0.1118 - val_acc: 0.9647\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0518 - acc: 0.9823 - val_loss: 0.0800 - val_acc: 0.9797\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0557 - acc: 0.9817 - val_loss: 0.0893 - val_acc: 0.9797\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0416 - acc: 0.9877 - val_loss: 0.1457 - val_acc: 0.9573\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0516 - acc: 0.9841 - val_loss: 0.0914 - val_acc: 0.9690\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0452 - acc: 0.9859 - val_loss: 0.0842 - val_acc: 0.9765\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0658 - acc: 0.9805 - val_loss: 0.0976 - val_acc: 0.9701\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0350 - acc: 0.9898 - val_loss: 0.1448 - val_acc: 0.9594\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0297 - acc: 0.9913 - val_loss: 0.0719 - val_acc: 0.9818\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0305 - acc: 0.9895 - val_loss: 0.0739 - val_acc: 0.9797\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0358 - acc: 0.9871 - val_loss: 0.6316 - val_acc: 0.8216\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0423 - acc: 0.9901 - val_loss: 0.1008 - val_acc: 0.9744\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 419us/step - loss: 1.3806 - acc: 0.4202 - val_loss: 1.2607 - val_acc: 0.3675\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: 1.0479 - acc: 0.5635 - val_loss: 0.8742 - val_acc: 0.6581\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.8881 - acc: 0.6440 - val_loss: 0.9841 - val_acc: 0.6207\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.7277 - acc: 0.7309 - val_loss: 4.1771 - val_acc: 0.4006\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.6911 - acc: 0.7714 - val_loss: 0.5264 - val_acc: 0.8024\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.5663 - acc: 0.7885 - val_loss: 0.6060 - val_acc: 0.7756\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.4817 - acc: 0.8282 - val_loss: 0.3604 - val_acc: 0.8835\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.4001 - acc: 0.8645 - val_loss: 0.4288 - val_acc: 0.8333\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.3923 - acc: 0.8654 - val_loss: 0.3373 - val_acc: 0.8803\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.3085 - acc: 0.8904 - val_loss: 0.3953 - val_acc: 0.8686\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2866 - acc: 0.8967 - val_loss: 0.2614 - val_acc: 0.9071\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.3010 - acc: 0.8946 - val_loss: 0.3504 - val_acc: 0.8761\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2057 - acc: 0.9264 - val_loss: 0.1806 - val_acc: 0.9423\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.2139 - acc: 0.9246 - val_loss: 0.1567 - val_acc: 0.9530\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1719 - acc: 0.9402 - val_loss: 0.2041 - val_acc: 0.9455\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.1576 - acc: 0.9456 - val_loss: 0.3057 - val_acc: 0.8857\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.1572 - acc: 0.9468 - val_loss: 0.2116 - val_acc: 0.9231\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: 0.1255 - acc: 0.9591 - val_loss: 0.1828 - val_acc: 0.9370\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.1527 - acc: 0.9468 - val_loss: 0.2315 - val_acc: 0.9199\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.1140 - acc: 0.9631 - val_loss: 0.0984 - val_acc: 0.9658\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1079 - acc: 0.9619 - val_loss: 0.1025 - val_acc: 0.9658\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0957 - acc: 0.9709 - val_loss: 0.1068 - val_acc: 0.9637\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0808 - acc: 0.9760 - val_loss: 0.0896 - val_acc: 0.9679\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0797 - acc: 0.9733 - val_loss: 0.0992 - val_acc: 0.9690\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1132 - acc: 0.9640 - val_loss: 0.0861 - val_acc: 0.9733\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0595 - acc: 0.9832 - val_loss: 0.0922 - val_acc: 0.9690\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0647 - acc: 0.9814 - val_loss: 0.0920 - val_acc: 0.9701\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0553 - acc: 0.9817 - val_loss: 0.1099 - val_acc: 0.9669\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0732 - acc: 0.9763 - val_loss: 0.2638 - val_acc: 0.9263\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0589 - acc: 0.9844 - val_loss: 0.0753 - val_acc: 0.9776\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0506 - acc: 0.9838 - val_loss: 0.0762 - val_acc: 0.9754\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0382 - acc: 0.9883 - val_loss: 0.0777 - val_acc: 0.9744\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0455 - acc: 0.9859 - val_loss: 0.0719 - val_acc: 0.9765\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0472 - acc: 0.9856 - val_loss: 0.0711 - val_acc: 0.9776\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0509 - acc: 0.9850 - val_loss: 0.0671 - val_acc: 0.9818\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0305 - acc: 0.9901 - val_loss: 0.0783 - val_acc: 0.9733\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0355 - acc: 0.9910 - val_loss: 0.0565 - val_acc: 0.9808\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0407 - acc: 0.9883 - val_loss: 0.0629 - val_acc: 0.9818\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0251 - acc: 0.9928 - val_loss: 0.0569 - val_acc: 0.9797\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0316 - acc: 0.9898 - val_loss: 0.0524 - val_acc: 0.9840\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0200 - acc: 0.9958 - val_loss: 0.0565 - val_acc: 0.9818\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0633 - val_acc: 0.9818\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0216 - acc: 0.9949 - val_loss: 0.0559 - val_acc: 0.9818\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0273 - acc: 0.9910 - val_loss: 0.3149 - val_acc: 0.9006\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0332 - acc: 0.9895 - val_loss: 0.0537 - val_acc: 0.9818\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0140 - acc: 0.9964 - val_loss: 0.0592 - val_acc: 0.9797\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0195 - acc: 0.9937 - val_loss: 0.0832 - val_acc: 0.9765\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: 0.0163 - acc: 0.9955 - val_loss: 0.0796 - val_acc: 0.9765\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: 0.0398 - acc: 0.9916 - val_loss: 0.0616 - val_acc: 0.9808\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0111 - acc: 0.9970 - val_loss: 0.0464 - val_acc: 0.9861\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in [32, 64, 128, 256]:\n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(i, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                    optimizer=keras.optimizers.Adadelta(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['dense_layer_size', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dense_layer_size</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0.984380</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.947705</td>\n",
       "      <td>20.118898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.997597</td>\n",
       "      <td>0.976496</td>\n",
       "      <td>0.970117</td>\n",
       "      <td>20.350231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.997597</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.975454</td>\n",
       "      <td>20.993096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>23.157206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dense_layer_size  training_accuracy  validation_accuracy  test_accuracy  \\\n",
       "0                32           0.984380             0.957265       0.947705   \n",
       "1                64           0.997597             0.976496       0.970117   \n",
       "2               128           0.997597             0.974359       0.975454   \n",
       "3               256           1.000000             0.986111       0.976521   \n",
       "\n",
       "    run_time  \n",
       "0  20.118898  \n",
       "1  20.350231  \n",
       "2  20.993096  \n",
       "3  23.157206  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 442us/step - loss: 1.3701 - acc: 0.4296 - val_loss: 1.4568 - val_acc: 0.3323\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 1.1043 - acc: 0.5491 - val_loss: 0.8781 - val_acc: 0.6827\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.9076 - acc: 0.6552 - val_loss: 0.8076 - val_acc: 0.6870\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.7881 - acc: 0.7044 - val_loss: 0.7865 - val_acc: 0.7382\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.6890 - acc: 0.7369 - val_loss: 0.6717 - val_acc: 0.7489\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.5753 - acc: 0.7909 - val_loss: 0.5341 - val_acc: 0.7853\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.5191 - acc: 0.8105 - val_loss: 0.7880 - val_acc: 0.7254\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.4568 - acc: 0.8309 - val_loss: 0.3876 - val_acc: 0.8643\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.3900 - acc: 0.8603 - val_loss: 0.3612 - val_acc: 0.8739\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.3416 - acc: 0.8753 - val_loss: 0.3124 - val_acc: 0.8953\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.3038 - acc: 0.8994 - val_loss: 0.2290 - val_acc: 0.9316\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2540 - acc: 0.9129 - val_loss: 1.9059 - val_acc: 0.5876\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2420 - acc: 0.9261 - val_loss: 0.1965 - val_acc: 0.9306\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1912 - acc: 0.9387 - val_loss: 0.4350 - val_acc: 0.8568\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.1998 - acc: 0.9318 - val_loss: 0.1845 - val_acc: 0.9391\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1560 - acc: 0.9501 - val_loss: 0.1931 - val_acc: 0.9391\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.1460 - acc: 0.9480 - val_loss: 0.4214 - val_acc: 0.8365\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1386 - acc: 0.9528 - val_loss: 0.1299 - val_acc: 0.9594\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.1526 - acc: 0.9525 - val_loss: 0.1618 - val_acc: 0.9476\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0948 - acc: 0.9706 - val_loss: 0.5304 - val_acc: 0.8547\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.1042 - acc: 0.9691 - val_loss: 0.1254 - val_acc: 0.9594\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0910 - acc: 0.9715 - val_loss: 0.1016 - val_acc: 0.9658\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0902 - acc: 0.9703 - val_loss: 0.1108 - val_acc: 0.9679\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0647 - acc: 0.9820 - val_loss: 0.1054 - val_acc: 0.9701\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0824 - acc: 0.9730 - val_loss: 0.1044 - val_acc: 0.9690\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0859 - acc: 0.9721 - val_loss: 0.1158 - val_acc: 0.9637\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0553 - acc: 0.9847 - val_loss: 0.1100 - val_acc: 0.9594\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0737 - acc: 0.9763 - val_loss: 0.5514 - val_acc: 0.8376\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0744 - acc: 0.9823 - val_loss: 0.0837 - val_acc: 0.9658\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0447 - acc: 0.9871 - val_loss: 0.0904 - val_acc: 0.9712\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0557 - acc: 0.9832 - val_loss: 0.0830 - val_acc: 0.9722\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0466 - acc: 0.9859 - val_loss: 0.0659 - val_acc: 0.9786\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0527 - acc: 0.9850 - val_loss: 0.0673 - val_acc: 0.9818\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0438 - acc: 0.9856 - val_loss: 0.3000 - val_acc: 0.9156\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0423 - acc: 0.9880 - val_loss: 0.1079 - val_acc: 0.9722\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0422 - acc: 0.9895 - val_loss: 0.5494 - val_acc: 0.8152\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0355 - acc: 0.9892 - val_loss: 0.9207 - val_acc: 0.8248\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0535 - acc: 0.9856 - val_loss: 0.0581 - val_acc: 0.9808\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0209 - acc: 0.9949 - val_loss: 0.0663 - val_acc: 0.9754\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0214 - acc: 0.9949 - val_loss: 0.0872 - val_acc: 0.9690\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0240 - acc: 0.9937 - val_loss: 0.0679 - val_acc: 0.9754\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0360 - acc: 0.9898 - val_loss: 0.0749 - val_acc: 0.9765\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0276 - acc: 0.9937 - val_loss: 0.0881 - val_acc: 0.9690\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.0601 - val_acc: 0.9808\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0260 - acc: 0.9898 - val_loss: 0.1009 - val_acc: 0.9712\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0218 - acc: 0.9934 - val_loss: 0.0599 - val_acc: 0.9808\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0215 - acc: 0.9943 - val_loss: 0.0949 - val_acc: 0.9754\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0616 - acc: 0.9832 - val_loss: 0.0690 - val_acc: 0.9808\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0185 - acc: 0.9952 - val_loss: 0.0605 - val_acc: 0.9840\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0161 - acc: 0.9952 - val_loss: 0.0816 - val_acc: 0.9797\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 438us/step - loss: 0.0671 - acc: 0.3983 - val_loss: 0.0845 - val_acc: 0.3857\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0597 - acc: 0.4842 - val_loss: 0.0654 - val_acc: 0.3697\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0557 - acc: 0.5149 - val_loss: 0.0575 - val_acc: 0.4936\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0532 - acc: 0.5446 - val_loss: 0.0717 - val_acc: 0.3526\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0509 - acc: 0.5758 - val_loss: 0.0790 - val_acc: 0.3985\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0493 - acc: 0.5975 - val_loss: 0.0478 - val_acc: 0.5897\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0455 - acc: 0.6344 - val_loss: 0.0488 - val_acc: 0.6058\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0455 - acc: 0.6305 - val_loss: 0.0513 - val_acc: 0.6261\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0421 - acc: 0.6645 - val_loss: 0.0373 - val_acc: 0.7115\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0403 - acc: 0.6819 - val_loss: 0.0398 - val_acc: 0.6976\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0384 - acc: 0.7044 - val_loss: 0.0411 - val_acc: 0.6218\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0374 - acc: 0.7125 - val_loss: 0.0369 - val_acc: 0.7041\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0356 - acc: 0.7287 - val_loss: 0.0366 - val_acc: 0.7115\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0342 - acc: 0.7318 - val_loss: 0.0314 - val_acc: 0.7682\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0332 - acc: 0.7429 - val_loss: 0.0307 - val_acc: 0.7618\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0318 - acc: 0.7555 - val_loss: 0.0279 - val_acc: 0.7853\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0306 - acc: 0.7654 - val_loss: 0.0265 - val_acc: 0.7917\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0293 - acc: 0.7786 - val_loss: 0.0281 - val_acc: 0.7853\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0279 - acc: 0.7858 - val_loss: 0.0550 - val_acc: 0.5662\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0278 - acc: 0.7855 - val_loss: 0.0345 - val_acc: 0.7457\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0271 - acc: 0.8005 - val_loss: 0.0227 - val_acc: 0.8248\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0256 - acc: 0.8047 - val_loss: 0.0205 - val_acc: 0.8494\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0248 - acc: 0.8159 - val_loss: 0.0198 - val_acc: 0.8504\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0233 - acc: 0.8249 - val_loss: 0.0681 - val_acc: 0.5556\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0249 - acc: 0.8123 - val_loss: 0.0474 - val_acc: 0.6442\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0232 - acc: 0.8285 - val_loss: 0.0375 - val_acc: 0.7212\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0222 - acc: 0.8384 - val_loss: 0.0178 - val_acc: 0.8622\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0211 - acc: 0.8504 - val_loss: 0.0448 - val_acc: 0.6165\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0206 - acc: 0.8486 - val_loss: 0.0192 - val_acc: 0.8579\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0198 - acc: 0.8522 - val_loss: 0.0416 - val_acc: 0.6976\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0197 - acc: 0.8564 - val_loss: 0.0327 - val_acc: 0.7585\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0184 - acc: 0.8669 - val_loss: 0.0146 - val_acc: 0.8932\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0175 - acc: 0.8765 - val_loss: 0.0158 - val_acc: 0.8825\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0171 - acc: 0.8765 - val_loss: 0.0128 - val_acc: 0.9167\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0161 - acc: 0.8871 - val_loss: 0.0157 - val_acc: 0.9006\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0155 - acc: 0.8937 - val_loss: 0.0166 - val_acc: 0.8771\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0152 - acc: 0.8913 - val_loss: 0.0146 - val_acc: 0.8953\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0151 - acc: 0.8958 - val_loss: 0.0278 - val_acc: 0.7906\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0152 - acc: 0.8901 - val_loss: 0.0114 - val_acc: 0.9220\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0139 - acc: 0.8991 - val_loss: 0.0103 - val_acc: 0.9295\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0144 - acc: 0.8958 - val_loss: 0.0699 - val_acc: 0.4637\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0155 - acc: 0.8889 - val_loss: 0.0104 - val_acc: 0.9252\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0132 - acc: 0.9060 - val_loss: 0.0097 - val_acc: 0.9338\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0121 - acc: 0.9165 - val_loss: 0.0750 - val_acc: 0.4957\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0143 - acc: 0.8988 - val_loss: 0.0090 - val_acc: 0.9370\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0110 - acc: 0.9264 - val_loss: 0.0101 - val_acc: 0.9338\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0111 - acc: 0.9234 - val_loss: 0.0142 - val_acc: 0.8996\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0119 - acc: 0.9156 - val_loss: 0.0248 - val_acc: 0.8066\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0124 - acc: 0.9129 - val_loss: 0.0146 - val_acc: 0.8996\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0111 - acc: 0.9219 - val_loss: 0.0098 - val_acc: 0.9327\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 443us/step - loss: 1.3773 - acc: 0.4233 - val_loss: 1.3473 - val_acc: 0.3494\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 1.0439 - acc: 0.5749 - val_loss: 1.4465 - val_acc: 0.5385\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.8956 - acc: 0.6570 - val_loss: 0.9281 - val_acc: 0.6368\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.7590 - acc: 0.7101 - val_loss: 0.6106 - val_acc: 0.7821\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.6550 - acc: 0.7528 - val_loss: 2.3675 - val_acc: 0.4647\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.6498 - acc: 0.7735 - val_loss: 0.6817 - val_acc: 0.7511\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.4930 - acc: 0.8246 - val_loss: 0.4641 - val_acc: 0.8419\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.4392 - acc: 0.8375 - val_loss: 0.3931 - val_acc: 0.8686\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.3883 - acc: 0.8648 - val_loss: 1.3519 - val_acc: 0.6175\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.3507 - acc: 0.8801 - val_loss: 0.4329 - val_acc: 0.8451\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.3066 - acc: 0.8886 - val_loss: 0.2485 - val_acc: 0.9263\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2772 - acc: 0.8988 - val_loss: 0.2344 - val_acc: 0.9295\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2270 - acc: 0.9237 - val_loss: 0.2190 - val_acc: 0.9209\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.1975 - acc: 0.9327 - val_loss: 0.2911 - val_acc: 0.9006\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1923 - acc: 0.9321 - val_loss: 0.2660 - val_acc: 0.8942\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.1751 - acc: 0.9459 - val_loss: 0.1742 - val_acc: 0.9412\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1518 - acc: 0.9498 - val_loss: 0.3510 - val_acc: 0.8889\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1586 - acc: 0.9492 - val_loss: 1.1406 - val_acc: 0.5812\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1558 - acc: 0.9528 - val_loss: 0.1204 - val_acc: 0.9594\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1060 - acc: 0.9664 - val_loss: 0.1628 - val_acc: 0.9402\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1067 - acc: 0.9676 - val_loss: 0.1207 - val_acc: 0.9551\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1219 - acc: 0.9582 - val_loss: 0.1254 - val_acc: 0.9626\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0788 - acc: 0.9763 - val_loss: 0.1033 - val_acc: 0.9626\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0733 - acc: 0.9793 - val_loss: 0.0948 - val_acc: 0.9690\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0742 - acc: 0.9757 - val_loss: 0.3467 - val_acc: 0.8771\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0819 - acc: 0.9745 - val_loss: 0.1086 - val_acc: 0.9690\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0672 - acc: 0.9793 - val_loss: 0.1120 - val_acc: 0.9658\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0958 - acc: 0.9673 - val_loss: 0.1733 - val_acc: 0.9455\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0573 - acc: 0.9814 - val_loss: 0.0867 - val_acc: 0.9754\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0567 - acc: 0.9829 - val_loss: 0.1271 - val_acc: 0.9573\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0555 - acc: 0.9832 - val_loss: 0.0980 - val_acc: 0.9712\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0449 - acc: 0.9886 - val_loss: 0.0848 - val_acc: 0.9776\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0599 - acc: 0.9841 - val_loss: 0.0807 - val_acc: 0.9765\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0559 - acc: 0.9814 - val_loss: 0.0977 - val_acc: 0.9712\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0354 - acc: 0.9886 - val_loss: 0.0963 - val_acc: 0.9669\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0395 - acc: 0.9886 - val_loss: 0.0773 - val_acc: 0.9808\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0434 - acc: 0.9865 - val_loss: 0.0792 - val_acc: 0.9829\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0288 - acc: 0.9928 - val_loss: 0.0882 - val_acc: 0.9679\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0489 - acc: 0.9847 - val_loss: 0.0835 - val_acc: 0.9701\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0299 - acc: 0.9907 - val_loss: 0.0704 - val_acc: 0.9786\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0173 - acc: 0.9958 - val_loss: 0.1120 - val_acc: 0.9637\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0290 - acc: 0.9892 - val_loss: 0.0805 - val_acc: 0.9733\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0367 - acc: 0.9898 - val_loss: 0.0874 - val_acc: 0.9744\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0253 - acc: 0.9919 - val_loss: 0.0878 - val_acc: 0.9765\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0139 - acc: 0.9970 - val_loss: 0.0741 - val_acc: 0.9818\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0300 - acc: 0.9919 - val_loss: 0.0962 - val_acc: 0.9722\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0159 - acc: 0.9967 - val_loss: 0.0699 - val_acc: 0.9765\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0220 - acc: 0.9928 - val_loss: 0.0892 - val_acc: 0.9765\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0572 - acc: 0.9832 - val_loss: 0.0770 - val_acc: 0.9776\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0139 - acc: 0.9964 - val_loss: 0.0800 - val_acc: 0.9797\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 474us/step - loss: 0.4807 - acc: 0.4136 - val_loss: 0.4729 - val_acc: 0.3654\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.4300 - acc: 0.5365 - val_loss: 0.4823 - val_acc: 0.5385\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.3987 - acc: 0.6008 - val_loss: 0.4123 - val_acc: 0.5759\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.3791 - acc: 0.6467 - val_loss: 0.3480 - val_acc: 0.7265\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.3628 - acc: 0.6771 - val_loss: 0.3678 - val_acc: 0.7094\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.3488 - acc: 0.7197 - val_loss: 0.3271 - val_acc: 0.7660\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.3389 - acc: 0.7327 - val_loss: 0.3320 - val_acc: 0.7382\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.3260 - acc: 0.7579 - val_loss: 0.3219 - val_acc: 0.7543\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.3150 - acc: 0.7837 - val_loss: 0.3192 - val_acc: 0.7810\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.3077 - acc: 0.7942 - val_loss: 0.2857 - val_acc: 0.8355\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2955 - acc: 0.8273 - val_loss: 0.2793 - val_acc: 0.8675\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2934 - acc: 0.8237 - val_loss: 0.5549 - val_acc: 0.5214\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2915 - acc: 0.8372 - val_loss: 0.2722 - val_acc: 0.8857\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2744 - acc: 0.8642 - val_loss: 0.3058 - val_acc: 0.7970\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2719 - acc: 0.8678 - val_loss: 0.3163 - val_acc: 0.7083\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.2688 - acc: 0.8732 - val_loss: 0.2534 - val_acc: 0.9199\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2652 - acc: 0.8825 - val_loss: 0.4319 - val_acc: 0.6132\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2618 - acc: 0.8979 - val_loss: 0.2564 - val_acc: 0.8974\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2501 - acc: 0.9132 - val_loss: 0.2639 - val_acc: 0.8878\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2514 - acc: 0.9090 - val_loss: 0.2608 - val_acc: 0.8921\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2439 - acc: 0.9258 - val_loss: 0.2406 - val_acc: 0.9370\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2427 - acc: 0.9249 - val_loss: 0.2342 - val_acc: 0.9498\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2415 - acc: 0.9267 - val_loss: 0.2355 - val_acc: 0.9391\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2388 - acc: 0.9342 - val_loss: 0.3023 - val_acc: 0.8152\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2347 - acc: 0.9453 - val_loss: 0.2309 - val_acc: 0.9412\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2290 - acc: 0.9495 - val_loss: 0.2339 - val_acc: 0.9444\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2314 - acc: 0.9444 - val_loss: 0.2262 - val_acc: 0.9551\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2281 - acc: 0.9549 - val_loss: 0.2273 - val_acc: 0.9530\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2271 - acc: 0.9555 - val_loss: 0.2368 - val_acc: 0.9348\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.2220 - acc: 0.9631 - val_loss: 0.2416 - val_acc: 0.9199\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2220 - acc: 0.9649 - val_loss: 0.2238 - val_acc: 0.9615\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2222 - acc: 0.9619 - val_loss: 0.2234 - val_acc: 0.9594\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.2165 - acc: 0.9757 - val_loss: 0.2218 - val_acc: 0.9583\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - ETA: 0s - loss: 0.2201 - acc: 0.967 - 0s 127us/step - loss: 0.2201 - acc: 0.9673 - val_loss: 0.2256 - val_acc: 0.9615\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2178 - acc: 0.9682 - val_loss: 0.3024 - val_acc: 0.8077\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2208 - acc: 0.9649 - val_loss: 0.2241 - val_acc: 0.9573\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2145 - acc: 0.9778 - val_loss: 0.2197 - val_acc: 0.9658\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2131 - acc: 0.9799 - val_loss: 0.2190 - val_acc: 0.9669\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2146 - acc: 0.9781 - val_loss: 0.2175 - val_acc: 0.9669\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2142 - acc: 0.9763 - val_loss: 0.2201 - val_acc: 0.9669\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2155 - acc: 0.9715 - val_loss: 0.2178 - val_acc: 0.9744\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2101 - acc: 0.9865 - val_loss: 0.2147 - val_acc: 0.9765\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2112 - acc: 0.9802 - val_loss: 0.2142 - val_acc: 0.9754\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2160 - acc: 0.9775 - val_loss: 0.2170 - val_acc: 0.9679\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2096 - acc: 0.9844 - val_loss: 0.2184 - val_acc: 0.9733\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2081 - acc: 0.9889 - val_loss: 0.2137 - val_acc: 0.9765\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2092 - acc: 0.9856 - val_loss: 0.2150 - val_acc: 0.9797\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2101 - acc: 0.9814 - val_loss: 0.2129 - val_acc: 0.9797\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.2099 - acc: 0.9862 - val_loss: 0.2120 - val_acc: 0.9808\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2064 - acc: 0.9922 - val_loss: 0.2161 - val_acc: 0.9712\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 487us/step - loss: -0.5400 - acc: 0.4226 - val_loss: -0.5406 - val_acc: 0.4829\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.6293 - acc: 0.5437 - val_loss: -0.6352 - val_acc: 0.5588\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.6858 - acc: 0.6239 - val_loss: -0.5404 - val_acc: 0.5053\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.7124 - acc: 0.6591 - val_loss: -0.6023 - val_acc: 0.5459\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.7522 - acc: 0.7068 - val_loss: -0.7361 - val_acc: 0.6966\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.7797 - acc: 0.7384 - val_loss: -0.7855 - val_acc: 0.7564\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.7989 - acc: 0.7609 - val_loss: -0.8391 - val_acc: 0.8098\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8178 - acc: 0.7867 - val_loss: -0.8474 - val_acc: 0.8194\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.8399 - acc: 0.8132 - val_loss: -0.8746 - val_acc: 0.8632\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8557 - acc: 0.8363 - val_loss: -0.6813 - val_acc: 0.6464\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8560 - acc: 0.8375 - val_loss: -0.8741 - val_acc: 0.8558\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8795 - acc: 0.8669 - val_loss: -0.8535 - val_acc: 0.8344\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8928 - acc: 0.8798 - val_loss: -0.9190 - val_acc: 0.9199\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8994 - acc: 0.8904 - val_loss: -0.8725 - val_acc: 0.8494\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9119 - acc: 0.9009 - val_loss: -0.9250 - val_acc: 0.9145\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9164 - acc: 0.9081 - val_loss: -0.7321 - val_acc: 0.6432\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9223 - acc: 0.9120 - val_loss: -0.9382 - val_acc: 0.9284\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9317 - acc: 0.9267 - val_loss: -0.9433 - val_acc: 0.9380\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9404 - acc: 0.9330 - val_loss: -0.9494 - val_acc: 0.9541\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9371 - acc: 0.9282 - val_loss: -0.9492 - val_acc: 0.9466\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9471 - acc: 0.9462 - val_loss: -0.9586 - val_acc: 0.9551\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9444 - acc: 0.9366 - val_loss: -0.9526 - val_acc: 0.9466\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9524 - acc: 0.9501 - val_loss: -0.9058 - val_acc: 0.8889\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9570 - acc: 0.9555 - val_loss: -0.9651 - val_acc: 0.9658\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9643 - acc: 0.9643 - val_loss: -0.9582 - val_acc: 0.9541\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9638 - acc: 0.9640 - val_loss: -0.9515 - val_acc: 0.9455\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9620 - acc: 0.9619 - val_loss: -0.9648 - val_acc: 0.9605\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9694 - acc: 0.9688 - val_loss: -0.9693 - val_acc: 0.9626\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9711 - acc: 0.9700 - val_loss: -0.9625 - val_acc: 0.9594\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9728 - acc: 0.9724 - val_loss: -0.9666 - val_acc: 0.9647\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9753 - acc: 0.9748 - val_loss: -0.9717 - val_acc: 0.9712\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9750 - acc: 0.9721 - val_loss: -0.9583 - val_acc: 0.9562\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9732 - acc: 0.9706 - val_loss: -0.9729 - val_acc: 0.9690\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9770 - acc: 0.9760 - val_loss: -0.9744 - val_acc: 0.9754\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9802 - acc: 0.9799 - val_loss: -0.9709 - val_acc: 0.9701\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9816 - acc: 0.9817 - val_loss: -0.9755 - val_acc: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9824 - acc: 0.9838 - val_loss: -0.9092 - val_acc: 0.8825\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9836 - acc: 0.9853 - val_loss: -0.9340 - val_acc: 0.9209\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9831 - acc: 0.9847 - val_loss: -0.9777 - val_acc: 0.9776\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9849 - acc: 0.9847 - val_loss: -0.9742 - val_acc: 0.9690\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9842 - acc: 0.9841 - val_loss: -0.9788 - val_acc: 0.9754\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9873 - acc: 0.9880 - val_loss: -0.9027 - val_acc: 0.8803\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9872 - acc: 0.9895 - val_loss: -0.9809 - val_acc: 0.9786\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9855 - acc: 0.9853 - val_loss: -0.9780 - val_acc: 0.9722\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9858 - acc: 0.9856 - val_loss: -0.9801 - val_acc: 0.9754\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9894 - acc: 0.9904 - val_loss: -0.9806 - val_acc: 0.9786\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9856 - acc: 0.9853 - val_loss: -0.9828 - val_acc: 0.9797\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9884 - acc: 0.9889 - val_loss: -0.9838 - val_acc: 0.9797\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9892 - acc: 0.9889 - val_loss: -0.9786 - val_acc: 0.9733\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9883 - acc: 0.9877 - val_loss: -0.9872 - val_acc: 0.9861\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 505us/step - loss: 0.0708 - acc: 0.4136 - val_loss: 0.0827 - val_acc: 0.3547\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0622 - acc: 0.4923 - val_loss: 0.0666 - val_acc: 0.4637\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0576 - acc: 0.5338 - val_loss: 0.0600 - val_acc: 0.4348\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0547 - acc: 0.5611 - val_loss: 0.0757 - val_acc: 0.3910\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0523 - acc: 0.5906 - val_loss: 0.0718 - val_acc: 0.4754\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0492 - acc: 0.6242 - val_loss: 0.0511 - val_acc: 0.5267\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0460 - acc: 0.6503 - val_loss: 0.0783 - val_acc: 0.4071\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0462 - acc: 0.6552 - val_loss: 0.0400 - val_acc: 0.7041\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0409 - acc: 0.7011 - val_loss: 0.0597 - val_acc: 0.5726\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: 0.0403 - acc: 0.7101 - val_loss: 0.0479 - val_acc: 0.6784\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0393 - acc: 0.7125 - val_loss: 0.0364 - val_acc: 0.7511\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0372 - acc: 0.7321 - val_loss: 0.0315 - val_acc: 0.7746\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0353 - acc: 0.7429 - val_loss: 0.0734 - val_acc: 0.5224\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0344 - acc: 0.7561 - val_loss: 0.0304 - val_acc: 0.7831\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0322 - acc: 0.7717 - val_loss: 0.0940 - val_acc: 0.4487\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0333 - acc: 0.7657 - val_loss: 0.0304 - val_acc: 0.7885\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0307 - acc: 0.7768 - val_loss: 0.0258 - val_acc: 0.8237\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: 0.0283 - acc: 0.8005 - val_loss: 0.0248 - val_acc: 0.8419\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0284 - acc: 0.8026 - val_loss: 0.0494 - val_acc: 0.6111\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0269 - acc: 0.8177 - val_loss: 0.0206 - val_acc: 0.8632\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0246 - acc: 0.8273 - val_loss: 0.0357 - val_acc: 0.7500\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0262 - acc: 0.8147 - val_loss: 0.0205 - val_acc: 0.8600\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0236 - acc: 0.8336 - val_loss: 0.0247 - val_acc: 0.8365\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0236 - acc: 0.8309 - val_loss: 0.0487 - val_acc: 0.6453\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0227 - acc: 0.8516 - val_loss: 0.0706 - val_acc: 0.5203\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0233 - acc: 0.8435 - val_loss: 0.0161 - val_acc: 0.9038\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0204 - acc: 0.8651 - val_loss: 0.0254 - val_acc: 0.8024\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0195 - acc: 0.8735 - val_loss: 0.0200 - val_acc: 0.8632\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0191 - acc: 0.8675 - val_loss: 0.0180 - val_acc: 0.8878\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0180 - acc: 0.8862 - val_loss: 0.0646 - val_acc: 0.5374\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0183 - acc: 0.8753 - val_loss: 0.0695 - val_acc: 0.5321\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0182 - acc: 0.8780 - val_loss: 0.0457 - val_acc: 0.6752\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0173 - acc: 0.8856 - val_loss: 0.0124 - val_acc: 0.9252\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0151 - acc: 0.8994 - val_loss: 0.0135 - val_acc: 0.9124\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0159 - acc: 0.8922 - val_loss: 0.0156 - val_acc: 0.8910\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0161 - acc: 0.8937 - val_loss: 0.0144 - val_acc: 0.9038\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: 0.0150 - acc: 0.9015 - val_loss: 0.0288 - val_acc: 0.7949\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: 0.0145 - acc: 0.9006 - val_loss: 0.0191 - val_acc: 0.8697\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: 0.0141 - acc: 0.9045 - val_loss: 0.0148 - val_acc: 0.8985\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: 0.0141 - acc: 0.9078 - val_loss: 0.0120 - val_acc: 0.9145\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: 0.0134 - acc: 0.9129 - val_loss: 0.0334 - val_acc: 0.7511\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0136 - acc: 0.9108 - val_loss: 0.0106 - val_acc: 0.9348\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0123 - acc: 0.9177 - val_loss: 0.0342 - val_acc: 0.7415\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0130 - acc: 0.9114 - val_loss: 0.0132 - val_acc: 0.9113\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0118 - acc: 0.9252 - val_loss: 0.0130 - val_acc: 0.9252\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: 0.0115 - acc: 0.9240 - val_loss: 0.0098 - val_acc: 0.9338\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: 0.0106 - acc: 0.9351 - val_loss: 0.0081 - val_acc: 0.9541\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: 0.0101 - acc: 0.9342 - val_loss: 0.0131 - val_acc: 0.9038\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: 0.0100 - acc: 0.9348 - val_loss: 0.0082 - val_acc: 0.9498\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: 0.0103 - acc: 0.9321 - val_loss: 0.0223 - val_acc: 0.8387\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in [keras.losses.categorical_crossentropy, keras.losses.logcosh,\n",
    "         keras.losses.kullback_leibler_divergence, keras.losses.poisson,\n",
    "         keras.losses.cosine_proximity, keras.losses.mean_squared_logarithmic_error]:\n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=i,\n",
    "                    optimizer=keras.optimizers.Adadelta(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['loss_function', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_function</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;function categorical_crossentropy at 0x7f2d6c...</td>\n",
       "      <td>0.998198</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.969050</td>\n",
       "      <td>22.877253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;function logcosh at 0x7f2d6c7f9a60&gt;</td>\n",
       "      <td>0.943827</td>\n",
       "      <td>0.932692</td>\n",
       "      <td>0.921025</td>\n",
       "      <td>22.466357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;function kullback_leibler_divergence at 0x7f2...</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>22.855597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;function poisson at 0x7f2d6c7f9d08&gt;</td>\n",
       "      <td>0.994893</td>\n",
       "      <td>0.971154</td>\n",
       "      <td>0.963714</td>\n",
       "      <td>22.742394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;function cosine_proximity at 0x7f2d6c7f9d90&gt;</td>\n",
       "      <td>0.996696</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>23.097623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;function mean_squared_logarithmic_error at 0x...</td>\n",
       "      <td>0.877441</td>\n",
       "      <td>0.838675</td>\n",
       "      <td>0.842049</td>\n",
       "      <td>23.796675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       loss_function  training_accuracy  \\\n",
       "0  <function categorical_crossentropy at 0x7f2d6c...           0.998198   \n",
       "1               <function logcosh at 0x7f2d6c7f9a60>           0.943827   \n",
       "2  <function kullback_leibler_divergence at 0x7f2...           0.999700   \n",
       "3               <function poisson at 0x7f2d6c7f9d08>           0.994893   \n",
       "4      <function cosine_proximity at 0x7f2d6c7f9d90>           0.996696   \n",
       "5  <function mean_squared_logarithmic_error at 0x...           0.877441   \n",
       "\n",
       "   validation_accuracy  test_accuracy   run_time  \n",
       "0             0.979701       0.969050  22.877253  \n",
       "1             0.932692       0.921025  22.466357  \n",
       "2             0.979701       0.974386  22.855597  \n",
       "3             0.971154       0.963714  22.742394  \n",
       "4             0.986111       0.976521  23.097623  \n",
       "5             0.838675       0.842049  23.796675  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 483us/step - loss: 1.4176 - acc: 0.4004 - val_loss: 1.4412 - val_acc: 0.3910\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 1.1338 - acc: 0.5308 - val_loss: 1.6488 - val_acc: 0.2628\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.9947 - acc: 0.5930 - val_loss: 0.8439 - val_acc: 0.6741\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.8710 - acc: 0.6558 - val_loss: 1.1497 - val_acc: 0.5876\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.7846 - acc: 0.6933 - val_loss: 1.0800 - val_acc: 0.5128\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.7052 - acc: 0.7336 - val_loss: 0.7320 - val_acc: 0.6538\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.6247 - acc: 0.7681 - val_loss: 0.5073 - val_acc: 0.8024\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.5369 - acc: 0.8050 - val_loss: 0.7389 - val_acc: 0.6261\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.4994 - acc: 0.8144 - val_loss: 0.4166 - val_acc: 0.8803\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.4700 - acc: 0.8291 - val_loss: 1.4169 - val_acc: 0.5833\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.4385 - acc: 0.8405 - val_loss: 0.7278 - val_acc: 0.7457\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.3726 - acc: 0.8621 - val_loss: 1.4533 - val_acc: 0.5684\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.3875 - acc: 0.8636 - val_loss: 0.3197 - val_acc: 0.8868\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.3396 - acc: 0.8816 - val_loss: 0.4656 - val_acc: 0.8205\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.3142 - acc: 0.8895 - val_loss: 0.2296 - val_acc: 0.9306\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.2936 - acc: 0.8982 - val_loss: 0.2398 - val_acc: 0.9199\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.2652 - acc: 0.9048 - val_loss: 0.1960 - val_acc: 0.9402\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2523 - acc: 0.9072 - val_loss: 0.1962 - val_acc: 0.9391\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.2395 - acc: 0.9198 - val_loss: 0.5660 - val_acc: 0.7639\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.2358 - acc: 0.9126 - val_loss: 0.1742 - val_acc: 0.9498\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.1869 - acc: 0.9357 - val_loss: 0.1679 - val_acc: 0.9476\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1859 - acc: 0.9366 - val_loss: 0.6520 - val_acc: 0.7682\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.1886 - acc: 0.9354 - val_loss: 0.1644 - val_acc: 0.9541\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.1579 - acc: 0.9435 - val_loss: 0.1383 - val_acc: 0.9605\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.1584 - acc: 0.9438 - val_loss: 0.1442 - val_acc: 0.9562\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.1636 - acc: 0.9447 - val_loss: 0.1712 - val_acc: 0.9444\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.1341 - acc: 0.9549 - val_loss: 0.1204 - val_acc: 0.9615\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1416 - acc: 0.9546 - val_loss: 0.1425 - val_acc: 0.9530\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1377 - acc: 0.9525 - val_loss: 0.1364 - val_acc: 0.9615\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.1163 - acc: 0.9640 - val_loss: 0.1326 - val_acc: 0.9541\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.1190 - acc: 0.9576 - val_loss: 0.4807 - val_acc: 0.8707\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1087 - acc: 0.9649 - val_loss: 0.1051 - val_acc: 0.9658\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1044 - acc: 0.9649 - val_loss: 0.2873 - val_acc: 0.8996\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0996 - acc: 0.9694 - val_loss: 0.1002 - val_acc: 0.9669\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0896 - acc: 0.9691 - val_loss: 0.0957 - val_acc: 0.9690\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1023 - acc: 0.9622 - val_loss: 0.0997 - val_acc: 0.9658\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0968 - acc: 0.9658 - val_loss: 0.6422 - val_acc: 0.7660\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0904 - acc: 0.9673 - val_loss: 0.0797 - val_acc: 0.9733\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0806 - acc: 0.9739 - val_loss: 0.1014 - val_acc: 0.9626\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0811 - acc: 0.9706 - val_loss: 0.6041 - val_acc: 0.8376\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.1086 - acc: 0.9664 - val_loss: 0.0865 - val_acc: 0.9765\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0533 - acc: 0.9847 - val_loss: 0.0907 - val_acc: 0.9647\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0741 - acc: 0.9781 - val_loss: 0.0692 - val_acc: 0.9754\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0535 - acc: 0.9820 - val_loss: 0.0736 - val_acc: 0.9765\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0866 - acc: 0.9685 - val_loss: 0.0771 - val_acc: 0.9744\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0640 - acc: 0.9805 - val_loss: 0.1561 - val_acc: 0.9434\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0722 - acc: 0.9757 - val_loss: 0.0821 - val_acc: 0.9765\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0476 - acc: 0.9865 - val_loss: 1.9507 - val_acc: 0.6784\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.1036 - acc: 0.9769 - val_loss: 0.0752 - val_acc: 0.9776\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0505 - acc: 0.9844 - val_loss: 0.0737 - val_acc: 0.9786\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 540us/step - loss: 0.0671 - acc: 0.3908 - val_loss: 0.0647 - val_acc: 0.3098\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0601 - acc: 0.4839 - val_loss: 0.0644 - val_acc: 0.3472\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0568 - acc: 0.5053 - val_loss: 0.0862 - val_acc: 0.3098\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0546 - acc: 0.5308 - val_loss: 0.0554 - val_acc: 0.4594\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0519 - acc: 0.5626 - val_loss: 0.0646 - val_acc: 0.4541\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0508 - acc: 0.5728 - val_loss: 0.0471 - val_acc: 0.6335\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0482 - acc: 0.5987 - val_loss: 0.0431 - val_acc: 0.6549\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0459 - acc: 0.6281 - val_loss: 0.0540 - val_acc: 0.5887\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0447 - acc: 0.6371 - val_loss: 0.0545 - val_acc: 0.6058\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0429 - acc: 0.6627 - val_loss: 0.0575 - val_acc: 0.5075\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0416 - acc: 0.6717 - val_loss: 0.0447 - val_acc: 0.6592\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0400 - acc: 0.6870 - val_loss: 0.0543 - val_acc: 0.5374\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0388 - acc: 0.6993 - val_loss: 0.0427 - val_acc: 0.6357\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0376 - acc: 0.7077 - val_loss: 0.0325 - val_acc: 0.7692\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0350 - acc: 0.7348 - val_loss: 0.0384 - val_acc: 0.7009\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0352 - acc: 0.7342 - val_loss: 0.0397 - val_acc: 0.7147\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0342 - acc: 0.7381 - val_loss: 0.0396 - val_acc: 0.6795\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0335 - acc: 0.7393 - val_loss: 0.0286 - val_acc: 0.7724\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0313 - acc: 0.7597 - val_loss: 0.0268 - val_acc: 0.7906\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0306 - acc: 0.7618 - val_loss: 0.0328 - val_acc: 0.7650\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0298 - acc: 0.7699 - val_loss: 0.0278 - val_acc: 0.7885\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0293 - acc: 0.7723 - val_loss: 0.0385 - val_acc: 0.7329\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0282 - acc: 0.7879 - val_loss: 0.0312 - val_acc: 0.7703\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0264 - acc: 0.8011 - val_loss: 0.0235 - val_acc: 0.8226\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0258 - acc: 0.8032 - val_loss: 0.0513 - val_acc: 0.6186\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0267 - acc: 0.7975 - val_loss: 0.0196 - val_acc: 0.8665\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0241 - acc: 0.8219 - val_loss: 0.0424 - val_acc: 0.7094\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0248 - acc: 0.8222 - val_loss: 0.0278 - val_acc: 0.7799\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0231 - acc: 0.8291 - val_loss: 0.0193 - val_acc: 0.8611\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0231 - acc: 0.8255 - val_loss: 0.0192 - val_acc: 0.8825\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0218 - acc: 0.8399 - val_loss: 0.0362 - val_acc: 0.6816\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0218 - acc: 0.8369 - val_loss: 0.0392 - val_acc: 0.6624\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0218 - acc: 0.8405 - val_loss: 0.0200 - val_acc: 0.8376\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0205 - acc: 0.8492 - val_loss: 0.0177 - val_acc: 0.8707\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0197 - acc: 0.8558 - val_loss: 0.0741 - val_acc: 0.5374\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0211 - acc: 0.8525 - val_loss: 0.0140 - val_acc: 0.9028\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0192 - acc: 0.8582 - val_loss: 0.0409 - val_acc: 0.7318\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0198 - acc: 0.8564 - val_loss: 0.0132 - val_acc: 0.9124\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0183 - acc: 0.8660 - val_loss: 0.0150 - val_acc: 0.8878\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: 0.0171 - acc: 0.8807 - val_loss: 0.0331 - val_acc: 0.7511\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: 0.0181 - acc: 0.8696 - val_loss: 0.0125 - val_acc: 0.9209\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0157 - acc: 0.8922 - val_loss: 0.0174 - val_acc: 0.8697\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0156 - acc: 0.8874 - val_loss: 0.0424 - val_acc: 0.6741\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0165 - acc: 0.8807 - val_loss: 0.0120 - val_acc: 0.9124\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0145 - acc: 0.8976 - val_loss: 0.0239 - val_acc: 0.8152\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0146 - acc: 0.8985 - val_loss: 0.0502 - val_acc: 0.6207\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.0160 - acc: 0.8856 - val_loss: 0.0108 - val_acc: 0.9209\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0128 - acc: 0.9108 - val_loss: 0.0106 - val_acc: 0.9274\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: 0.0137 - acc: 0.9057 - val_loss: 0.0746 - val_acc: 0.5342\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0162 - acc: 0.8895 - val_loss: 0.0108 - val_acc: 0.9295\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 599us/step - loss: 1.3742 - acc: 0.4242 - val_loss: 2.4142 - val_acc: 0.4145\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 1.1028 - acc: 0.5539 - val_loss: 1.1484 - val_acc: 0.5983\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.9090 - acc: 0.6419 - val_loss: 1.7742 - val_acc: 0.4274\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.8168 - acc: 0.6879 - val_loss: 1.5482 - val_acc: 0.5085\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.7032 - acc: 0.7405 - val_loss: 1.3743 - val_acc: 0.5096\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.6240 - acc: 0.7684 - val_loss: 0.5364 - val_acc: 0.7981\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.5447 - acc: 0.8023 - val_loss: 0.7356 - val_acc: 0.7511\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.5072 - acc: 0.8162 - val_loss: 0.6184 - val_acc: 0.7853\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.4415 - acc: 0.8480 - val_loss: 1.1899 - val_acc: 0.6197\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.3989 - acc: 0.8582 - val_loss: 0.2987 - val_acc: 0.9060\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.3563 - acc: 0.8741 - val_loss: 0.3132 - val_acc: 0.9049\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.3275 - acc: 0.8871 - val_loss: 0.4156 - val_acc: 0.8536\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.3054 - acc: 0.8934 - val_loss: 0.2378 - val_acc: 0.9231\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2771 - acc: 0.9018 - val_loss: 0.2481 - val_acc: 0.9135\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2334 - acc: 0.9210 - val_loss: 2.7489 - val_acc: 0.5502\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2578 - acc: 0.9189 - val_loss: 0.1641 - val_acc: 0.9487\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.1889 - acc: 0.9375 - val_loss: 0.1455 - val_acc: 0.9551\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1620 - acc: 0.9492 - val_loss: 0.1470 - val_acc: 0.9509\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1672 - acc: 0.9438 - val_loss: 0.1596 - val_acc: 0.9541\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1598 - acc: 0.9432 - val_loss: 0.2020 - val_acc: 0.9348\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.1519 - acc: 0.9531 - val_loss: 0.1587 - val_acc: 0.9541\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1278 - acc: 0.9585 - val_loss: 0.1271 - val_acc: 0.9594\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1315 - acc: 0.9534 - val_loss: 0.1072 - val_acc: 0.9690\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.1028 - acc: 0.9691 - val_loss: 0.0928 - val_acc: 0.9754\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.1167 - acc: 0.9643 - val_loss: 0.1120 - val_acc: 0.9605\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0970 - acc: 0.9706 - val_loss: 0.0966 - val_acc: 0.9733\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0853 - acc: 0.9730 - val_loss: 0.1052 - val_acc: 0.9722\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0836 - acc: 0.9736 - val_loss: 0.0934 - val_acc: 0.9658\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0930 - acc: 0.9706 - val_loss: 0.0895 - val_acc: 0.9765\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0708 - acc: 0.9796 - val_loss: 2.7364 - val_acc: 0.5833\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.1355 - acc: 0.9667 - val_loss: 0.0767 - val_acc: 0.9744\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0527 - acc: 0.9859 - val_loss: 0.0711 - val_acc: 0.9786\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0535 - acc: 0.9808 - val_loss: 0.0892 - val_acc: 0.9765\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0709 - acc: 0.9796 - val_loss: 0.0741 - val_acc: 0.9765\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0497 - acc: 0.9847 - val_loss: 0.0684 - val_acc: 0.9797\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0674 - acc: 0.9775 - val_loss: 0.0698 - val_acc: 0.9797\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0575 - acc: 0.9838 - val_loss: 0.1038 - val_acc: 0.9722\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0363 - acc: 0.9895 - val_loss: 0.0884 - val_acc: 0.9712\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0377 - acc: 0.9889 - val_loss: 0.0834 - val_acc: 0.9776\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0711 - acc: 0.9796 - val_loss: 0.4084 - val_acc: 0.8387\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0499 - acc: 0.9859 - val_loss: 0.0671 - val_acc: 0.9786\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: 0.0399 - acc: 0.9856 - val_loss: 0.0931 - val_acc: 0.9722\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0442 - acc: 0.9853 - val_loss: 0.0611 - val_acc: 0.9808\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0546 - acc: 0.9826 - val_loss: 0.0891 - val_acc: 0.9733\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0290 - acc: 0.9922 - val_loss: 0.0671 - val_acc: 0.9808\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0392 - acc: 0.9880 - val_loss: 0.0989 - val_acc: 0.9615\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.0363 - acc: 0.9850 - val_loss: 0.1433 - val_acc: 0.9530\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0353 - acc: 0.9907 - val_loss: 0.0662 - val_acc: 0.9818\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.0351 - acc: 0.9892 - val_loss: 0.0599 - val_acc: 0.9829\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0344 - acc: 0.9895 - val_loss: 0.0740 - val_acc: 0.9808\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 533us/step - loss: 0.4811 - acc: 0.4115 - val_loss: 0.4482 - val_acc: 0.4124\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.4304 - acc: 0.5224 - val_loss: 0.4362 - val_acc: 0.4583\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.4036 - acc: 0.5876 - val_loss: 0.4646 - val_acc: 0.4113\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.3886 - acc: 0.6263 - val_loss: 0.4376 - val_acc: 0.5278\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.3694 - acc: 0.6654 - val_loss: 0.3999 - val_acc: 0.6111\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.3573 - acc: 0.7047 - val_loss: 0.3822 - val_acc: 0.6741\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.3409 - acc: 0.7363 - val_loss: 0.3686 - val_acc: 0.6806\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.3309 - acc: 0.7594 - val_loss: 0.7271 - val_acc: 0.3323\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.3310 - acc: 0.7630 - val_loss: 0.2987 - val_acc: 0.8088\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.3089 - acc: 0.7993 - val_loss: 0.2962 - val_acc: 0.8152\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.3041 - acc: 0.8017 - val_loss: 0.2973 - val_acc: 0.8216\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2973 - acc: 0.8183 - val_loss: 0.3353 - val_acc: 0.6859\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2968 - acc: 0.8234 - val_loss: 0.2881 - val_acc: 0.8451\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2873 - acc: 0.8363 - val_loss: 0.3637 - val_acc: 0.6175\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2806 - acc: 0.8585 - val_loss: 0.4179 - val_acc: 0.6784\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2770 - acc: 0.8627 - val_loss: 0.2612 - val_acc: 0.8974\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2696 - acc: 0.8819 - val_loss: 0.2572 - val_acc: 0.9006\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2634 - acc: 0.8856 - val_loss: 0.2651 - val_acc: 0.8846\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2607 - acc: 0.8946 - val_loss: 0.4021 - val_acc: 0.6410\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2631 - acc: 0.8886 - val_loss: 0.3339 - val_acc: 0.7073\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2576 - acc: 0.8955 - val_loss: 0.3085 - val_acc: 0.8109\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2518 - acc: 0.9078 - val_loss: 0.2469 - val_acc: 0.9209\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2445 - acc: 0.9198 - val_loss: 0.2439 - val_acc: 0.9177\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: 0.2497 - acc: 0.9129 - val_loss: 0.2906 - val_acc: 0.8483\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2467 - acc: 0.9159 - val_loss: 0.4387 - val_acc: 0.6132\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2436 - acc: 0.9222 - val_loss: 0.3200 - val_acc: 0.8312\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2406 - acc: 0.9282 - val_loss: 0.2345 - val_acc: 0.9412\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2352 - acc: 0.9369 - val_loss: 0.4513 - val_acc: 0.6111\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2378 - acc: 0.9396 - val_loss: 0.2753 - val_acc: 0.8494\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2347 - acc: 0.9432 - val_loss: 0.6357 - val_acc: 0.5994\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2404 - acc: 0.9423 - val_loss: 0.2715 - val_acc: 0.8643\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2294 - acc: 0.9531 - val_loss: 0.2217 - val_acc: 0.9605\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2273 - acc: 0.9555 - val_loss: 0.2350 - val_acc: 0.9412\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.2302 - acc: 0.9504 - val_loss: 0.2270 - val_acc: 0.9615\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2250 - acc: 0.9591 - val_loss: 0.2435 - val_acc: 0.9284\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2276 - acc: 0.9579 - val_loss: 0.2209 - val_acc: 0.9615\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2234 - acc: 0.9643 - val_loss: 0.2223 - val_acc: 0.9615\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2248 - acc: 0.9570 - val_loss: 0.2440 - val_acc: 0.9252\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2230 - acc: 0.9612 - val_loss: 0.2201 - val_acc: 0.9658\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2219 - acc: 0.9655 - val_loss: 0.2247 - val_acc: 0.9605\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2201 - acc: 0.9694 - val_loss: 0.2170 - val_acc: 0.9712\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2185 - acc: 0.9697 - val_loss: 0.2278 - val_acc: 0.9541\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2197 - acc: 0.9658 - val_loss: 0.2211 - val_acc: 0.9679\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2200 - acc: 0.9652 - val_loss: 0.2195 - val_acc: 0.9669\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.2169 - acc: 0.9742 - val_loss: 0.2180 - val_acc: 0.9647\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.2139 - acc: 0.9769 - val_loss: 0.2222 - val_acc: 0.9669\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: 0.2166 - acc: 0.9712 - val_loss: 0.2155 - val_acc: 0.9754\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.2174 - acc: 0.9736 - val_loss: 0.2154 - val_acc: 0.9754\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2146 - acc: 0.9772 - val_loss: 0.2147 - val_acc: 0.9733\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: 0.2191 - acc: 0.9682 - val_loss: 0.2681 - val_acc: 0.8889\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 570us/step - loss: -0.5397 - acc: 0.4214 - val_loss: -0.5231 - val_acc: 0.4081\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.6217 - acc: 0.5422 - val_loss: -0.6482 - val_acc: 0.5545\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.6707 - acc: 0.5966 - val_loss: -0.5747 - val_acc: 0.5021\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.7169 - acc: 0.6618 - val_loss: -0.7093 - val_acc: 0.6389\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.7554 - acc: 0.7185 - val_loss: -0.7668 - val_acc: 0.7265\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.7674 - acc: 0.7236 - val_loss: -0.5398 - val_acc: 0.3846\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.7910 - acc: 0.7585 - val_loss: -0.6261 - val_acc: 0.5513\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.8146 - acc: 0.7843 - val_loss: -0.8272 - val_acc: 0.8066\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.8294 - acc: 0.8002 - val_loss: -0.6477 - val_acc: 0.5748\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8309 - acc: 0.8056 - val_loss: -0.8594 - val_acc: 0.8376\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8622 - acc: 0.8435 - val_loss: -0.8843 - val_acc: 0.8697\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8676 - acc: 0.8504 - val_loss: -0.7995 - val_acc: 0.7596\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8689 - acc: 0.8480 - val_loss: -0.9078 - val_acc: 0.8985\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8843 - acc: 0.8678 - val_loss: -0.9053 - val_acc: 0.8942\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.8868 - acc: 0.8702 - val_loss: -0.7974 - val_acc: 0.7607\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8960 - acc: 0.8819 - val_loss: -0.9096 - val_acc: 0.9028\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9097 - acc: 0.9018 - val_loss: -0.9199 - val_acc: 0.9145\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9069 - acc: 0.8931 - val_loss: -0.9317 - val_acc: 0.9252\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9141 - acc: 0.9060 - val_loss: -0.8345 - val_acc: 0.7927\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9199 - acc: 0.9069 - val_loss: -0.9386 - val_acc: 0.9359\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9204 - acc: 0.9144 - val_loss: -0.9468 - val_acc: 0.9466\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9288 - acc: 0.9231 - val_loss: -0.9199 - val_acc: 0.9092\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9332 - acc: 0.9255 - val_loss: -0.9520 - val_acc: 0.9487\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9325 - acc: 0.9264 - val_loss: -0.9490 - val_acc: 0.9423\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9406 - acc: 0.9351 - val_loss: -0.9319 - val_acc: 0.9177\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9448 - acc: 0.9405 - val_loss: -0.6363 - val_acc: 0.5994\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9379 - acc: 0.9357 - val_loss: -0.9151 - val_acc: 0.8996\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9510 - acc: 0.9429 - val_loss: -0.9510 - val_acc: 0.9487\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9507 - acc: 0.9441 - val_loss: -0.9598 - val_acc: 0.9615\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9573 - acc: 0.9534 - val_loss: -0.9615 - val_acc: 0.9605\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9566 - acc: 0.9549 - val_loss: -0.9650 - val_acc: 0.9573\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9607 - acc: 0.9576 - val_loss: -0.9616 - val_acc: 0.9551\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9663 - acc: 0.9652 - val_loss: -0.9475 - val_acc: 0.9412\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9571 - acc: 0.9528 - val_loss: -0.9696 - val_acc: 0.9647\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9706 - acc: 0.9733 - val_loss: -0.8480 - val_acc: 0.8024\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9662 - acc: 0.9655 - val_loss: -0.9688 - val_acc: 0.9658\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9692 - acc: 0.9691 - val_loss: -0.9692 - val_acc: 0.9658\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9703 - acc: 0.9685 - val_loss: -0.9711 - val_acc: 0.9669\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9736 - acc: 0.9742 - val_loss: -0.9714 - val_acc: 0.9690\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9717 - acc: 0.9694 - val_loss: -0.9666 - val_acc: 0.9669\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9687 - acc: 0.9664 - val_loss: -0.6586 - val_acc: 0.6004\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9686 - acc: 0.9676 - val_loss: -0.9479 - val_acc: 0.9380\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9783 - acc: 0.9799 - val_loss: -0.9759 - val_acc: 0.9722\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9758 - acc: 0.9742 - val_loss: -0.9750 - val_acc: 0.9744\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9794 - acc: 0.9772 - val_loss: -0.9737 - val_acc: 0.9658\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9688 - acc: 0.9661 - val_loss: -0.9684 - val_acc: 0.9637\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9756 - acc: 0.9739 - val_loss: -0.9770 - val_acc: 0.9733\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9825 - acc: 0.9823 - val_loss: -0.9738 - val_acc: 0.9669\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9784 - acc: 0.9769 - val_loss: -0.9770 - val_acc: 0.9733\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9783 - acc: 0.9763 - val_loss: -0.9670 - val_acc: 0.9647\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 572us/step - loss: 0.0708 - acc: 0.4037 - val_loss: 0.0678 - val_acc: 0.4776\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0626 - acc: 0.4905 - val_loss: 0.0555 - val_acc: 0.5620\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0575 - acc: 0.5365 - val_loss: 0.0596 - val_acc: 0.5342\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0540 - acc: 0.5816 - val_loss: 0.0487 - val_acc: 0.6111\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0509 - acc: 0.5996 - val_loss: 0.0509 - val_acc: 0.5929\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0492 - acc: 0.6164 - val_loss: 0.0460 - val_acc: 0.6421\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0469 - acc: 0.6494 - val_loss: 0.0513 - val_acc: 0.6100\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0450 - acc: 0.6675 - val_loss: 0.0477 - val_acc: 0.6357\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0430 - acc: 0.6813 - val_loss: 0.0518 - val_acc: 0.6197\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0410 - acc: 0.6993 - val_loss: 0.0397 - val_acc: 0.7201\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0385 - acc: 0.7152 - val_loss: 0.0345 - val_acc: 0.7425\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0366 - acc: 0.7357 - val_loss: 0.0449 - val_acc: 0.6015\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0354 - acc: 0.7471 - val_loss: 0.0751 - val_acc: 0.5224\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: 0.0355 - acc: 0.7414 - val_loss: 0.0302 - val_acc: 0.7970\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0323 - acc: 0.7747 - val_loss: 0.0281 - val_acc: 0.8152\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0322 - acc: 0.7723 - val_loss: 0.0338 - val_acc: 0.7479\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0301 - acc: 0.7837 - val_loss: 0.0313 - val_acc: 0.7746\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0280 - acc: 0.8078 - val_loss: 0.0499 - val_acc: 0.6859\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0294 - acc: 0.7906 - val_loss: 0.0223 - val_acc: 0.8397\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0280 - acc: 0.8081 - val_loss: 0.0493 - val_acc: 0.7051\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0275 - acc: 0.8099 - val_loss: 0.0476 - val_acc: 0.6218\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0249 - acc: 0.8297 - val_loss: 0.0224 - val_acc: 0.8355\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: 0.0247 - acc: 0.8297 - val_loss: 0.0486 - val_acc: 0.5983\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0235 - acc: 0.8363 - val_loss: 0.0172 - val_acc: 0.8889\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0231 - acc: 0.8441 - val_loss: 0.0336 - val_acc: 0.7703\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: 0.0211 - acc: 0.8594 - val_loss: 0.0229 - val_acc: 0.8387\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: 0.0214 - acc: 0.8513 - val_loss: 0.0329 - val_acc: 0.7564\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0207 - acc: 0.8594 - val_loss: 0.0142 - val_acc: 0.9327\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0204 - acc: 0.8597 - val_loss: 0.0360 - val_acc: 0.7436\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0189 - acc: 0.8762 - val_loss: 0.0136 - val_acc: 0.9145\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0180 - acc: 0.8825 - val_loss: 0.0556 - val_acc: 0.6122\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0192 - acc: 0.8714 - val_loss: 0.0191 - val_acc: 0.8654\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0174 - acc: 0.8828 - val_loss: 0.0704 - val_acc: 0.5459\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0203 - acc: 0.8645 - val_loss: 0.0168 - val_acc: 0.8857\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0156 - acc: 0.8970 - val_loss: 0.0457 - val_acc: 0.6741\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0167 - acc: 0.8859 - val_loss: 0.0141 - val_acc: 0.8996\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0159 - acc: 0.8985 - val_loss: 0.0210 - val_acc: 0.8483\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0152 - acc: 0.8979 - val_loss: 0.0471 - val_acc: 0.6571\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: 0.0163 - acc: 0.8943 - val_loss: 0.0114 - val_acc: 0.9306\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0136 - acc: 0.9123 - val_loss: 0.0170 - val_acc: 0.8803\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0146 - acc: 0.9036 - val_loss: 0.0140 - val_acc: 0.9199\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0141 - acc: 0.9075 - val_loss: 0.0147 - val_acc: 0.8974\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0149 - acc: 0.8991 - val_loss: 0.0098 - val_acc: 0.9359\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0134 - acc: 0.9150 - val_loss: 0.0089 - val_acc: 0.9466\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: 0.0130 - acc: 0.9144 - val_loss: 0.0101 - val_acc: 0.9327\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0126 - acc: 0.9207 - val_loss: 0.0085 - val_acc: 0.9519\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: 0.0126 - acc: 0.9156 - val_loss: 0.0096 - val_acc: 0.9391\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: 0.0123 - acc: 0.9234 - val_loss: 0.0094 - val_acc: 0.9466\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: 0.0113 - acc: 0.9285 - val_loss: 0.0216 - val_acc: 0.8365\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: 0.0118 - acc: 0.9192 - val_loss: 0.0082 - val_acc: 0.9519\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in [keras.losses.categorical_crossentropy, keras.losses.logcosh,\n",
    "         keras.losses.kullback_leibler_divergence, keras.losses.poisson,\n",
    "         keras.losses.cosine_proximity, keras.losses.mean_squared_logarithmic_error]:\n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=i,\n",
    "                    optimizer=keras.optimizers.Adadelta(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['loss_function', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_function</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;function categorical_crossentropy at 0x7f2d6c...</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.973319</td>\n",
       "      <td>22.441008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;function logcosh at 0x7f2d6c7f9a60&gt;</td>\n",
       "      <td>0.945629</td>\n",
       "      <td>0.929487</td>\n",
       "      <td>0.922092</td>\n",
       "      <td>21.633922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;function kullback_leibler_divergence at 0x7f2...</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.979723</td>\n",
       "      <td>22.448360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;function poisson at 0x7f2d6c7f9d08&gt;</td>\n",
       "      <td>0.918594</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.896478</td>\n",
       "      <td>22.154273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;function cosine_proximity at 0x7f2d6c7f9d90&gt;</td>\n",
       "      <td>0.988886</td>\n",
       "      <td>0.964744</td>\n",
       "      <td>0.956243</td>\n",
       "      <td>22.643988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;function mean_squared_logarithmic_error at 0x...</td>\n",
       "      <td>0.962752</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.938100</td>\n",
       "      <td>23.028781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       loss_function  training_accuracy  \\\n",
       "0  <function categorical_crossentropy at 0x7f2d6c...           0.999099   \n",
       "1               <function logcosh at 0x7f2d6c7f9a60>           0.945629   \n",
       "2  <function kullback_leibler_divergence at 0x7f2...           0.999099   \n",
       "3               <function poisson at 0x7f2d6c7f9d08>           0.918594   \n",
       "4      <function cosine_proximity at 0x7f2d6c7f9d90>           0.988886   \n",
       "5  <function mean_squared_logarithmic_error at 0x...           0.962752   \n",
       "\n",
       "   validation_accuracy  test_accuracy   run_time  \n",
       "0             0.978632       0.973319  22.441008  \n",
       "1             0.929487       0.922092  21.633922  \n",
       "2             0.980769       0.979723  22.448360  \n",
       "3             0.888889       0.896478  22.154273  \n",
       "4             0.964744       0.956243  22.643988  \n",
       "5             0.951923       0.938100  23.028781  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 8s 2ms/step - loss: -0.5332 - acc: 0.4139 - val_loss: -0.5866 - val_acc: 0.5780\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.6317 - acc: 0.5614 - val_loss: -0.4632 - val_acc: 0.3451\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.6725 - acc: 0.6041 - val_loss: -0.6762 - val_acc: 0.6186\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.7223 - acc: 0.6705 - val_loss: -0.7236 - val_acc: 0.6624\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.7572 - acc: 0.7158 - val_loss: -0.5714 - val_acc: 0.5032\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.7753 - acc: 0.7414 - val_loss: -0.7312 - val_acc: 0.6656\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.7971 - acc: 0.7600 - val_loss: -0.6062 - val_acc: 0.5406\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.8129 - acc: 0.7837 - val_loss: -0.8429 - val_acc: 0.8226\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8307 - acc: 0.8102 - val_loss: -0.8724 - val_acc: 0.8622\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.8500 - acc: 0.8306 - val_loss: -0.7213 - val_acc: 0.6902\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.8620 - acc: 0.8459 - val_loss: -0.8922 - val_acc: 0.8803\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8847 - acc: 0.8705 - val_loss: -0.7501 - val_acc: 0.6987\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.8837 - acc: 0.8693 - val_loss: -0.8457 - val_acc: 0.8259\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9006 - acc: 0.8943 - val_loss: -0.8723 - val_acc: 0.8558\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9046 - acc: 0.8946 - val_loss: -0.9254 - val_acc: 0.9156\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9099 - acc: 0.9015 - val_loss: -0.9361 - val_acc: 0.9380\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9245 - acc: 0.9198 - val_loss: -0.9344 - val_acc: 0.9316\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9202 - acc: 0.9114 - val_loss: -0.9394 - val_acc: 0.9359\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9302 - acc: 0.9252 - val_loss: -0.9415 - val_acc: 0.9476\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9428 - acc: 0.9387 - val_loss: -0.9505 - val_acc: 0.9605\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9403 - acc: 0.9375 - val_loss: -0.9393 - val_acc: 0.9316\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9419 - acc: 0.9366 - val_loss: -0.9272 - val_acc: 0.9167\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9472 - acc: 0.9435 - val_loss: -0.9600 - val_acc: 0.9530\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9541 - acc: 0.9513 - val_loss: -0.9569 - val_acc: 0.9605\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9543 - acc: 0.9525 - val_loss: -0.9507 - val_acc: 0.9476\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9600 - acc: 0.9603 - val_loss: -0.9629 - val_acc: 0.9605\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9592 - acc: 0.9591 - val_loss: -0.9555 - val_acc: 0.9541\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9639 - acc: 0.9634 - val_loss: -0.9692 - val_acc: 0.9647\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9651 - acc: 0.9646 - val_loss: -0.9581 - val_acc: 0.9498\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9685 - acc: 0.9703 - val_loss: -0.9583 - val_acc: 0.9562\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9689 - acc: 0.9658 - val_loss: -0.9532 - val_acc: 0.9487\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9717 - acc: 0.9709 - val_loss: -0.9424 - val_acc: 0.9252\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9712 - acc: 0.9721 - val_loss: -0.8232 - val_acc: 0.7853\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9757 - acc: 0.9763 - val_loss: -0.9676 - val_acc: 0.9647\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9745 - acc: 0.9739 - val_loss: -0.9779 - val_acc: 0.9722\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9805 - acc: 0.9826 - val_loss: -0.9692 - val_acc: 0.9658\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9796 - acc: 0.9799 - val_loss: -0.9633 - val_acc: 0.9605\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9726 - acc: 0.9688 - val_loss: -0.9726 - val_acc: 0.9722\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9810 - acc: 0.9805 - val_loss: -0.9756 - val_acc: 0.9712\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9842 - acc: 0.9838 - val_loss: -0.9751 - val_acc: 0.9754\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9838 - acc: 0.9844 - val_loss: -0.9795 - val_acc: 0.9733\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9777 - acc: 0.9751 - val_loss: -0.9788 - val_acc: 0.9765\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9854 - acc: 0.9871 - val_loss: -0.9779 - val_acc: 0.9733\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9845 - acc: 0.9844 - val_loss: -0.9783 - val_acc: 0.9744\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9836 - acc: 0.9820 - val_loss: -0.9823 - val_acc: 0.9797\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9873 - acc: 0.9877 - val_loss: -0.9826 - val_acc: 0.9797\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9756 - acc: 0.9742 - val_loss: -0.9793 - val_acc: 0.9733\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9908 - acc: 0.9913 - val_loss: -0.9838 - val_acc: 0.9818\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9882 - acc: 0.9895 - val_loss: -0.9833 - val_acc: 0.9797\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9859 - acc: 0.9868 - val_loss: -0.8712 - val_acc: 0.8494\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 272us/step - loss: -0.4933 - acc: 0.3899 - val_loss: -0.5861 - val_acc: 0.4989\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.6835 - acc: 0.6206 - val_loss: -0.2341 - val_acc: 0.1944\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.6654 - acc: 0.6284 - val_loss: -0.8188 - val_acc: 0.7959\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.8002 - acc: 0.7636 - val_loss: -0.8208 - val_acc: 0.8130\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.8364 - acc: 0.8144 - val_loss: -0.8378 - val_acc: 0.8152\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.8637 - acc: 0.8504 - val_loss: -0.8652 - val_acc: 0.8462\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.8824 - acc: 0.8741 - val_loss: -0.8510 - val_acc: 0.8141\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.8933 - acc: 0.8786 - val_loss: -0.9105 - val_acc: 0.8996\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9050 - acc: 0.9012 - val_loss: -0.9193 - val_acc: 0.9081\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.9120 - acc: 0.9018 - val_loss: -0.9227 - val_acc: 0.9124\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.9241 - acc: 0.9198 - val_loss: -0.9351 - val_acc: 0.9263\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.9342 - acc: 0.9327 - val_loss: -0.9365 - val_acc: 0.9295\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9389 - acc: 0.9369 - val_loss: -0.9411 - val_acc: 0.9380\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9440 - acc: 0.9420 - val_loss: -0.9415 - val_acc: 0.9359\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9477 - acc: 0.9462 - val_loss: -0.9438 - val_acc: 0.9391\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9499 - acc: 0.9471 - val_loss: -0.9443 - val_acc: 0.9402\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9558 - acc: 0.9546 - val_loss: -0.9545 - val_acc: 0.9530\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9563 - acc: 0.9552 - val_loss: -0.9474 - val_acc: 0.9423\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9610 - acc: 0.9606 - val_loss: -0.9544 - val_acc: 0.9476\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9622 - acc: 0.9646 - val_loss: -0.9585 - val_acc: 0.9530\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9631 - acc: 0.9634 - val_loss: -0.9575 - val_acc: 0.9573\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9663 - acc: 0.9679 - val_loss: -0.9595 - val_acc: 0.9541\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9691 - acc: 0.9706 - val_loss: -0.9182 - val_acc: 0.9071\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9688 - acc: 0.9700 - val_loss: -0.9630 - val_acc: 0.9562\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.9704 - acc: 0.9700 - val_loss: -0.9597 - val_acc: 0.9573\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9752 - acc: 0.9787 - val_loss: -0.9648 - val_acc: 0.9637\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9768 - acc: 0.9793 - val_loss: -0.9664 - val_acc: 0.9637\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.9757 - acc: 0.9784 - val_loss: -0.9648 - val_acc: 0.9626\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9782 - acc: 0.9814 - val_loss: -0.9660 - val_acc: 0.9626\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9748 - acc: 0.9775 - val_loss: -0.9654 - val_acc: 0.9647\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9781 - acc: 0.9811 - val_loss: -0.9693 - val_acc: 0.9669\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9810 - acc: 0.9847 - val_loss: -0.9692 - val_acc: 0.9647\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9816 - acc: 0.9844 - val_loss: -0.9649 - val_acc: 0.9583\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9826 - acc: 0.9847 - val_loss: -0.9570 - val_acc: 0.9498\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9812 - acc: 0.9844 - val_loss: -0.9697 - val_acc: 0.9701\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9823 - acc: 0.9856 - val_loss: -0.9719 - val_acc: 0.9712\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9840 - acc: 0.9859 - val_loss: -0.9730 - val_acc: 0.9733\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9836 - acc: 0.9853 - val_loss: -0.9734 - val_acc: 0.9765\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9845 - acc: 0.9868 - val_loss: -0.9716 - val_acc: 0.9690\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9857 - acc: 0.9880 - val_loss: -0.9727 - val_acc: 0.9733\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9848 - acc: 0.9868 - val_loss: -0.9723 - val_acc: 0.9701\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9864 - acc: 0.9898 - val_loss: -0.9742 - val_acc: 0.9754\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9848 - acc: 0.9868 - val_loss: -0.9744 - val_acc: 0.9722\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9863 - acc: 0.9880 - val_loss: -0.9743 - val_acc: 0.9712\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9884 - acc: 0.9898 - val_loss: -0.9744 - val_acc: 0.9701\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9890 - acc: 0.9904 - val_loss: -0.9754 - val_acc: 0.9733\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9873 - acc: 0.9904 - val_loss: -0.9763 - val_acc: 0.9733\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9901 - acc: 0.9925 - val_loss: -0.9750 - val_acc: 0.9722\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9898 - acc: 0.9922 - val_loss: -0.9778 - val_acc: 0.9797\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9895 - acc: 0.9910 - val_loss: -0.9748 - val_acc: 0.9744\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 282us/step - loss: -0.5902 - acc: 0.4944 - val_loss: -0.4992 - val_acc: 0.4466\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.7319 - acc: 0.6870 - val_loss: -0.4548 - val_acc: 0.4284\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.7676 - acc: 0.7321 - val_loss: -0.5485 - val_acc: 0.5278\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.8162 - acc: 0.7840 - val_loss: -0.7973 - val_acc: 0.7521\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.8516 - acc: 0.8267 - val_loss: -0.7153 - val_acc: 0.6571\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.8727 - acc: 0.8504 - val_loss: -0.8326 - val_acc: 0.8013\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.8903 - acc: 0.8771 - val_loss: -0.8513 - val_acc: 0.8130\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9017 - acc: 0.8913 - val_loss: -0.9138 - val_acc: 0.9017\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9116 - acc: 0.8982 - val_loss: -0.6271 - val_acc: 0.5855\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9202 - acc: 0.9069 - val_loss: -0.9147 - val_acc: 0.9017\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9340 - acc: 0.9252 - val_loss: -0.9326 - val_acc: 0.9241\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9397 - acc: 0.9318 - val_loss: -0.9475 - val_acc: 0.9402\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9423 - acc: 0.9315 - val_loss: -0.9496 - val_acc: 0.9402\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9536 - acc: 0.9498 - val_loss: -0.9531 - val_acc: 0.9423\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9560 - acc: 0.9495 - val_loss: -0.9110 - val_acc: 0.8868\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9571 - acc: 0.9510 - val_loss: -0.9609 - val_acc: 0.9573\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9627 - acc: 0.9570 - val_loss: -0.9503 - val_acc: 0.9423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9683 - acc: 0.9658 - val_loss: -0.9558 - val_acc: 0.9509\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9685 - acc: 0.9655 - val_loss: -0.6935 - val_acc: 0.6816\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9560 - acc: 0.9504 - val_loss: -0.9665 - val_acc: 0.9615\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9722 - acc: 0.9688 - val_loss: -0.9609 - val_acc: 0.9573\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9762 - acc: 0.9739 - val_loss: -0.9374 - val_acc: 0.9274\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9789 - acc: 0.9790 - val_loss: -0.9626 - val_acc: 0.9647\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9758 - acc: 0.9730 - val_loss: -0.9707 - val_acc: 0.9669\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9803 - acc: 0.9793 - val_loss: -0.9663 - val_acc: 0.9605\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9815 - acc: 0.9787 - val_loss: -0.9725 - val_acc: 0.9679\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9830 - acc: 0.9802 - val_loss: -0.9694 - val_acc: 0.9637\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9753 - acc: 0.9724 - val_loss: -0.9664 - val_acc: 0.9605\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9820 - acc: 0.9805 - val_loss: -0.9716 - val_acc: 0.9669\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9830 - acc: 0.9793 - val_loss: -0.9732 - val_acc: 0.9712\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9854 - acc: 0.9850 - val_loss: -0.9115 - val_acc: 0.8921\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9804 - acc: 0.9763 - val_loss: -0.9729 - val_acc: 0.9679\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9818 - acc: 0.9790 - val_loss: -0.9761 - val_acc: 0.9733\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9861 - acc: 0.9844 - val_loss: -0.9773 - val_acc: 0.9744\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9862 - acc: 0.9850 - val_loss: -0.9675 - val_acc: 0.9647\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9853 - acc: 0.9820 - val_loss: -0.9762 - val_acc: 0.9733\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9908 - acc: 0.9898 - val_loss: -0.9763 - val_acc: 0.9712\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9898 - acc: 0.9895 - val_loss: -0.9202 - val_acc: 0.9113\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9880 - acc: 0.9856 - val_loss: -0.9633 - val_acc: 0.9573\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9895 - acc: 0.9886 - val_loss: -0.9799 - val_acc: 0.9765\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9904 - acc: 0.9895 - val_loss: -0.9731 - val_acc: 0.9690\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9892 - acc: 0.9886 - val_loss: -0.9773 - val_acc: 0.9765\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9883 - acc: 0.9868 - val_loss: -0.9779 - val_acc: 0.9754\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9918 - acc: 0.9907 - val_loss: -0.9755 - val_acc: 0.9733\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9916 - acc: 0.9922 - val_loss: -0.9800 - val_acc: 0.9765\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9900 - acc: 0.9889 - val_loss: -0.8868 - val_acc: 0.8622\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9901 - acc: 0.9880 - val_loss: -0.9659 - val_acc: 0.9573\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9916 - acc: 0.9901 - val_loss: -0.9777 - val_acc: 0.9744\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9901 - acc: 0.9892 - val_loss: -0.9827 - val_acc: 0.9818\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9920 - acc: 0.9895 - val_loss: -0.9823 - val_acc: 0.9797\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 321us/step - loss: -0.5094 - acc: 0.4169 - val_loss: -0.6312 - val_acc: 0.5491\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6943 - acc: 0.6293 - val_loss: -0.7589 - val_acc: 0.7019\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.7479 - acc: 0.6921 - val_loss: -0.8181 - val_acc: 0.7949\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.7861 - acc: 0.7441 - val_loss: -0.6093 - val_acc: 0.5406\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.8331 - acc: 0.8087 - val_loss: -0.6629 - val_acc: 0.6293\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.8585 - acc: 0.8342 - val_loss: -0.8799 - val_acc: 0.8590\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.8705 - acc: 0.8450 - val_loss: -0.8528 - val_acc: 0.8216\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.8879 - acc: 0.8705 - val_loss: -0.9138 - val_acc: 0.9017\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9021 - acc: 0.8850 - val_loss: -0.6782 - val_acc: 0.6239\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9051 - acc: 0.8925 - val_loss: -0.7342 - val_acc: 0.7190\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9055 - acc: 0.8916 - val_loss: -0.8726 - val_acc: 0.8526\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9276 - acc: 0.9144 - val_loss: -0.9168 - val_acc: 0.9071\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9290 - acc: 0.9138 - val_loss: -0.8758 - val_acc: 0.8494\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9456 - acc: 0.9375 - val_loss: -0.9415 - val_acc: 0.9348\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9419 - acc: 0.9321 - val_loss: -0.5639 - val_acc: 0.5513\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9243 - acc: 0.9165 - val_loss: -0.9487 - val_acc: 0.9423\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9509 - acc: 0.9414 - val_loss: -0.9504 - val_acc: 0.9434\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9583 - acc: 0.9522 - val_loss: -0.9108 - val_acc: 0.9006\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9541 - acc: 0.9453 - val_loss: -0.9585 - val_acc: 0.9509\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9557 - acc: 0.9471 - val_loss: -0.9536 - val_acc: 0.9455\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9671 - acc: 0.9640 - val_loss: -0.9521 - val_acc: 0.9466\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9616 - acc: 0.9573 - val_loss: -0.9530 - val_acc: 0.9498\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9653 - acc: 0.9609 - val_loss: -0.8059 - val_acc: 0.7842\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9635 - acc: 0.9591 - val_loss: -0.9617 - val_acc: 0.9530\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9649 - acc: 0.9594 - val_loss: -0.8979 - val_acc: 0.8825\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9640 - acc: 0.9588 - val_loss: -0.9560 - val_acc: 0.9476\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9673 - acc: 0.9612 - val_loss: -0.9422 - val_acc: 0.9348\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9716 - acc: 0.9667 - val_loss: -0.9356 - val_acc: 0.9263\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9742 - acc: 0.9700 - val_loss: -0.8815 - val_acc: 0.8697\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9695 - acc: 0.9652 - val_loss: -0.9565 - val_acc: 0.9498\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9763 - acc: 0.9742 - val_loss: -0.9669 - val_acc: 0.9626\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9673 - acc: 0.9634 - val_loss: -0.9540 - val_acc: 0.9509\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9757 - acc: 0.9715 - val_loss: -0.9637 - val_acc: 0.9594\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9755 - acc: 0.9721 - val_loss: -0.9678 - val_acc: 0.9626\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9684 - acc: 0.9643 - val_loss: -0.9686 - val_acc: 0.9658\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9740 - acc: 0.9724 - val_loss: -0.9603 - val_acc: 0.9519\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9660 - acc: 0.9619 - val_loss: -0.9643 - val_acc: 0.9615\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9765 - acc: 0.9727 - val_loss: -0.9714 - val_acc: 0.9669\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9755 - acc: 0.9709 - val_loss: -0.9639 - val_acc: 0.9594\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9755 - acc: 0.9730 - val_loss: -0.9656 - val_acc: 0.9615\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9789 - acc: 0.9763 - val_loss: -0.9590 - val_acc: 0.9573\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9765 - acc: 0.9742 - val_loss: -0.9659 - val_acc: 0.9626\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9780 - acc: 0.9754 - val_loss: -0.9703 - val_acc: 0.9669\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9817 - acc: 0.9793 - val_loss: -0.9256 - val_acc: 0.9199\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9773 - acc: 0.9754 - val_loss: -0.9687 - val_acc: 0.9658\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9802 - acc: 0.9775 - val_loss: -0.9650 - val_acc: 0.9626\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9793 - acc: 0.9769 - val_loss: -0.9675 - val_acc: 0.9647\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9816 - acc: 0.9793 - val_loss: -0.9636 - val_acc: 0.9583\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9782 - acc: 0.9751 - val_loss: -0.9400 - val_acc: 0.9316\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9820 - acc: 0.9793 - val_loss: -0.9677 - val_acc: 0.9626\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 288us/step - loss: -0.4636 - acc: 0.3025 - val_loss: -0.4819 - val_acc: 0.3526\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.4970 - acc: 0.4112 - val_loss: -0.5198 - val_acc: 0.3333\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.5344 - acc: 0.4578 - val_loss: -0.5200 - val_acc: 0.4049\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.5546 - acc: 0.4698 - val_loss: -0.5376 - val_acc: 0.4060\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.5670 - acc: 0.4692 - val_loss: -0.5524 - val_acc: 0.4295\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.5780 - acc: 0.4854 - val_loss: -0.5930 - val_acc: 0.5075\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.5921 - acc: 0.5005 - val_loss: -0.5677 - val_acc: 0.3889\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 104us/step - loss: -0.5948 - acc: 0.5038 - val_loss: -0.5739 - val_acc: 0.4338\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 103us/step - loss: -0.5957 - acc: 0.4983 - val_loss: -0.5883 - val_acc: 0.5192\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 100us/step - loss: -0.6070 - acc: 0.5125 - val_loss: -0.6168 - val_acc: 0.4658\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 102us/step - loss: -0.6153 - acc: 0.5284 - val_loss: -0.6279 - val_acc: 0.5363\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.6200 - acc: 0.5263 - val_loss: -0.6358 - val_acc: 0.5513\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.6206 - acc: 0.5326 - val_loss: -0.6352 - val_acc: 0.5513\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.6229 - acc: 0.5365 - val_loss: -0.5752 - val_acc: 0.5107\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.6209 - acc: 0.5329 - val_loss: -0.6234 - val_acc: 0.5075\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6302 - acc: 0.5458 - val_loss: -0.6314 - val_acc: 0.5385\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6379 - acc: 0.5641 - val_loss: -0.6198 - val_acc: 0.5385\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.6382 - acc: 0.5587 - val_loss: -0.6694 - val_acc: 0.6100\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.6437 - acc: 0.5695 - val_loss: -0.6236 - val_acc: 0.5427\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6466 - acc: 0.5689 - val_loss: -0.6584 - val_acc: 0.5609\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6516 - acc: 0.5831 - val_loss: -0.6577 - val_acc: 0.5876\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.6537 - acc: 0.5795 - val_loss: -0.4836 - val_acc: 0.4252\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.6254 - acc: 0.5512 - val_loss: -0.6583 - val_acc: 0.5716\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6603 - acc: 0.5903 - val_loss: -0.6934 - val_acc: 0.6474\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.6661 - acc: 0.5888 - val_loss: -0.6895 - val_acc: 0.6186\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6693 - acc: 0.6026 - val_loss: -0.5266 - val_acc: 0.4423\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.6577 - acc: 0.5870 - val_loss: -0.6926 - val_acc: 0.6207\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.6726 - acc: 0.6056 - val_loss: -0.7094 - val_acc: 0.6774\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6778 - acc: 0.6092 - val_loss: -0.7104 - val_acc: 0.6838\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6811 - acc: 0.6209 - val_loss: -0.7122 - val_acc: 0.6848\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6876 - acc: 0.6329 - val_loss: -0.7153 - val_acc: 0.6709\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6892 - acc: 0.6323 - val_loss: -0.5868 - val_acc: 0.4882\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6917 - acc: 0.6326 - val_loss: -0.5799 - val_acc: 0.5353\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.6652 - acc: 0.6020 - val_loss: -0.6868 - val_acc: 0.6432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.6888 - acc: 0.6302 - val_loss: -0.7232 - val_acc: 0.6955\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.6953 - acc: 0.6461 - val_loss: -0.7059 - val_acc: 0.6389\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.7022 - acc: 0.6518 - val_loss: -0.7264 - val_acc: 0.6838\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.7055 - acc: 0.6579 - val_loss: -0.7338 - val_acc: 0.6976\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.7047 - acc: 0.6540 - val_loss: -0.6886 - val_acc: 0.6453\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.7058 - acc: 0.6518 - val_loss: -0.6471 - val_acc: 0.5160\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.7027 - acc: 0.6452 - val_loss: -0.6507 - val_acc: 0.6015\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.7075 - acc: 0.6558 - val_loss: -0.7298 - val_acc: 0.6795\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.7132 - acc: 0.6660 - val_loss: -0.6512 - val_acc: 0.5929\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.7040 - acc: 0.6540 - val_loss: -0.6609 - val_acc: 0.6058\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.7140 - acc: 0.6612 - val_loss: -0.6081 - val_acc: 0.5053\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.7065 - acc: 0.6579 - val_loss: -0.7477 - val_acc: 0.7041\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.7227 - acc: 0.6726 - val_loss: -0.5628 - val_acc: 0.4829\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.7143 - acc: 0.6627 - val_loss: -0.7497 - val_acc: 0.7019\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.7270 - acc: 0.6825 - val_loss: -0.7059 - val_acc: 0.6528\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.7247 - acc: 0.6729 - val_loss: -0.7500 - val_acc: 0.7041\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 324us/step - loss: -0.4908 - acc: 0.3683 - val_loss: -0.5087 - val_acc: 0.3932\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.5488 - acc: 0.4539 - val_loss: -0.5704 - val_acc: 0.4327\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.5814 - acc: 0.4920 - val_loss: -0.5579 - val_acc: 0.3793\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.5895 - acc: 0.4956 - val_loss: -0.6204 - val_acc: 0.5310\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.6080 - acc: 0.5158 - val_loss: -0.4376 - val_acc: 0.3547\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.5872 - acc: 0.4857 - val_loss: -0.5480 - val_acc: 0.3974\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.6121 - acc: 0.5251 - val_loss: -0.6352 - val_acc: 0.5545\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.6228 - acc: 0.5314 - val_loss: -0.6156 - val_acc: 0.5353\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.6303 - acc: 0.5476 - val_loss: -0.5227 - val_acc: 0.4733\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.6223 - acc: 0.5392 - val_loss: -0.6165 - val_acc: 0.5406\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.6307 - acc: 0.5509 - val_loss: -0.6582 - val_acc: 0.5684\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.6411 - acc: 0.5623 - val_loss: -0.6324 - val_acc: 0.5534\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.6479 - acc: 0.5767 - val_loss: -0.6009 - val_acc: 0.4380\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.6481 - acc: 0.5792 - val_loss: -0.6156 - val_acc: 0.5620\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.6561 - acc: 0.5903 - val_loss: -0.5458 - val_acc: 0.4263\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.6555 - acc: 0.5864 - val_loss: -0.5547 - val_acc: 0.4712\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.6489 - acc: 0.5783 - val_loss: -0.6156 - val_acc: 0.5171\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.6707 - acc: 0.6017 - val_loss: -0.6157 - val_acc: 0.5096\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.6750 - acc: 0.6131 - val_loss: -0.4529 - val_acc: 0.2810\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.6683 - acc: 0.6056 - val_loss: -0.5619 - val_acc: 0.5203\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.6681 - acc: 0.6062 - val_loss: -0.6264 - val_acc: 0.5684\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.6774 - acc: 0.6194 - val_loss: -0.7049 - val_acc: 0.6656\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.6996 - acc: 0.6473 - val_loss: -0.5358 - val_acc: 0.3814\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.6844 - acc: 0.6350 - val_loss: -0.7369 - val_acc: 0.7115\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.7108 - acc: 0.6645 - val_loss: -0.7078 - val_acc: 0.6688\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.7169 - acc: 0.6690 - val_loss: -0.6010 - val_acc: 0.5726\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.7062 - acc: 0.6630 - val_loss: -0.5643 - val_acc: 0.4476\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.7008 - acc: 0.6555 - val_loss: -0.7463 - val_acc: 0.7115\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.7244 - acc: 0.6786 - val_loss: -0.7145 - val_acc: 0.6688\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.7287 - acc: 0.6819 - val_loss: -0.7270 - val_acc: 0.6944\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.7390 - acc: 0.6996 - val_loss: -0.5704 - val_acc: 0.4786\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.7295 - acc: 0.6903 - val_loss: -0.5557 - val_acc: 0.4605\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.7183 - acc: 0.6699 - val_loss: -0.4998 - val_acc: 0.4551\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.7043 - acc: 0.6582 - val_loss: -0.7610 - val_acc: 0.7201\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.7480 - acc: 0.7071 - val_loss: -0.5132 - val_acc: 0.4594\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.7088 - acc: 0.6612 - val_loss: -0.7500 - val_acc: 0.6934\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.7516 - acc: 0.7161 - val_loss: -0.6810 - val_acc: 0.6197\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.7407 - acc: 0.7014 - val_loss: -0.7476 - val_acc: 0.7179\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.7578 - acc: 0.7179 - val_loss: -0.5939 - val_acc: 0.5427\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.7162 - acc: 0.6699 - val_loss: -0.7592 - val_acc: 0.7286\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.7580 - acc: 0.7218 - val_loss: -0.6094 - val_acc: 0.4936\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.7540 - acc: 0.7197 - val_loss: -0.7508 - val_acc: 0.6592\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.7662 - acc: 0.7333 - val_loss: -0.7874 - val_acc: 0.7468\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.7728 - acc: 0.7366 - val_loss: -0.7224 - val_acc: 0.6079\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.7680 - acc: 0.7269 - val_loss: -0.5565 - val_acc: 0.4947\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.7576 - acc: 0.7218 - val_loss: -0.7978 - val_acc: 0.7553\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 105us/step - loss: -0.7771 - acc: 0.7438 - val_loss: -0.7006 - val_acc: 0.6207\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 107us/step - loss: -0.7703 - acc: 0.7309 - val_loss: -0.8045 - val_acc: 0.7799\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.7793 - acc: 0.7474 - val_loss: -0.7567 - val_acc: 0.7073\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.7807 - acc: 0.7450 - val_loss: -0.4422 - val_acc: 0.3942\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 1s 422us/step - loss: -0.5725 - acc: 0.4662 - val_loss: -0.5616 - val_acc: 0.4284\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.7152 - acc: 0.6549 - val_loss: -0.5240 - val_acc: 0.3803\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.7646 - acc: 0.7161 - val_loss: -0.6337 - val_acc: 0.5427\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.8260 - acc: 0.7945 - val_loss: -0.8408 - val_acc: 0.8045\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.8717 - acc: 0.8525 - val_loss: -0.9001 - val_acc: 0.8814\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.8992 - acc: 0.8853 - val_loss: -0.9115 - val_acc: 0.8964\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9171 - acc: 0.9057 - val_loss: -0.9027 - val_acc: 0.8889\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9155 - acc: 0.9045 - val_loss: -0.3855 - val_acc: 0.3408\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8542 - acc: 0.8306 - val_loss: -0.9098 - val_acc: 0.8985\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9206 - acc: 0.9108 - val_loss: -0.9395 - val_acc: 0.9316\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9448 - acc: 0.9420 - val_loss: -0.9481 - val_acc: 0.9412\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9471 - acc: 0.9408 - val_loss: -0.9235 - val_acc: 0.9071\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9484 - acc: 0.9411 - val_loss: -0.9472 - val_acc: 0.9391\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9610 - acc: 0.9585 - val_loss: -0.9579 - val_acc: 0.9498\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9671 - acc: 0.9646 - val_loss: -0.9596 - val_acc: 0.9562\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9685 - acc: 0.9664 - val_loss: -0.9509 - val_acc: 0.9380\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9706 - acc: 0.9691 - val_loss: -0.9634 - val_acc: 0.9583\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9769 - acc: 0.9736 - val_loss: -0.9695 - val_acc: 0.9658\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9782 - acc: 0.9766 - val_loss: -0.9303 - val_acc: 0.9124\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9661 - acc: 0.9625 - val_loss: -0.9616 - val_acc: 0.9519\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9779 - acc: 0.9769 - val_loss: -0.9672 - val_acc: 0.9626\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9805 - acc: 0.9778 - val_loss: -0.9558 - val_acc: 0.9476\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9818 - acc: 0.9787 - val_loss: -0.9729 - val_acc: 0.9690\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9812 - acc: 0.9805 - val_loss: -0.9599 - val_acc: 0.9530\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9844 - acc: 0.9850 - val_loss: -0.9647 - val_acc: 0.9615\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9792 - acc: 0.9769 - val_loss: -0.9765 - val_acc: 0.9754\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9849 - acc: 0.9838 - val_loss: -0.9509 - val_acc: 0.9444\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9887 - acc: 0.9880 - val_loss: -0.9692 - val_acc: 0.9679\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9840 - acc: 0.9817 - val_loss: -0.9731 - val_acc: 0.9690\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9886 - acc: 0.9880 - val_loss: -0.9741 - val_acc: 0.9701\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9887 - acc: 0.9889 - val_loss: -0.9762 - val_acc: 0.9744\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9887 - acc: 0.9892 - val_loss: -0.9746 - val_acc: 0.9733\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9869 - acc: 0.9847 - val_loss: -0.9695 - val_acc: 0.9690\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9892 - acc: 0.9886 - val_loss: -0.9717 - val_acc: 0.9679\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9918 - acc: 0.9916 - val_loss: -0.9739 - val_acc: 0.9701\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9880 - acc: 0.9868 - val_loss: -0.9720 - val_acc: 0.9658\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9865 - acc: 0.9862 - val_loss: -0.9735 - val_acc: 0.9679\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9874 - acc: 0.9865 - val_loss: -0.9747 - val_acc: 0.9712\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9875 - acc: 0.9844 - val_loss: -0.9770 - val_acc: 0.9712\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9928 - acc: 0.9919 - val_loss: -0.9630 - val_acc: 0.9583\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9806 - acc: 0.9784 - val_loss: -0.9734 - val_acc: 0.9712\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.9900 - acc: 0.9895 - val_loss: -0.9713 - val_acc: 0.9658\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9876 - acc: 0.9853 - val_loss: -0.9551 - val_acc: 0.9519\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9827 - acc: 0.9799 - val_loss: -0.9756 - val_acc: 0.9733\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9881 - acc: 0.9868 - val_loss: -0.9722 - val_acc: 0.9669\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9903 - acc: 0.9895 - val_loss: -0.9739 - val_acc: 0.9701\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9862 - acc: 0.9856 - val_loss: -0.9594 - val_acc: 0.9530\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9896 - acc: 0.9886 - val_loss: -0.9748 - val_acc: 0.9712\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9931 - acc: 0.9925 - val_loss: -0.9745 - val_acc: 0.9712\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9913 - acc: 0.9904 - val_loss: -0.9727 - val_acc: 0.9690\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 1s 383us/step - loss: -0.5985 - acc: 0.5116 - val_loss: -0.7192 - val_acc: 0.6688\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.7324 - acc: 0.6960 - val_loss: -0.7798 - val_acc: 0.7553\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.7821 - acc: 0.7480 - val_loss: -0.8069 - val_acc: 0.7895\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.8187 - acc: 0.7960 - val_loss: -0.8353 - val_acc: 0.8194\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.8367 - acc: 0.8168 - val_loss: -0.8664 - val_acc: 0.8547\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.8611 - acc: 0.8513 - val_loss: -0.8691 - val_acc: 0.8526\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.8852 - acc: 0.8777 - val_loss: -0.8733 - val_acc: 0.8579\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.8878 - acc: 0.8783 - val_loss: -0.9114 - val_acc: 0.9145\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.8992 - acc: 0.8976 - val_loss: -0.9123 - val_acc: 0.9177\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9125 - acc: 0.9099 - val_loss: -0.9203 - val_acc: 0.9188\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.8987 - acc: 0.8895 - val_loss: -0.9156 - val_acc: 0.9071\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9241 - acc: 0.9222 - val_loss: -0.9349 - val_acc: 0.9316\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9288 - acc: 0.9288 - val_loss: -0.9335 - val_acc: 0.9295\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9325 - acc: 0.9315 - val_loss: -0.9389 - val_acc: 0.9402\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9386 - acc: 0.9426 - val_loss: -0.9431 - val_acc: 0.9348\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9412 - acc: 0.9396 - val_loss: -0.9439 - val_acc: 0.9391\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9454 - acc: 0.9462 - val_loss: -0.9499 - val_acc: 0.9434\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9488 - acc: 0.9498 - val_loss: -0.9537 - val_acc: 0.9476\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9541 - acc: 0.9552 - val_loss: -0.9498 - val_acc: 0.9487\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9554 - acc: 0.9567 - val_loss: -0.9526 - val_acc: 0.9466\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9600 - acc: 0.9622 - val_loss: -0.9604 - val_acc: 0.9551\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9570 - acc: 0.9564 - val_loss: -0.9522 - val_acc: 0.9519\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9614 - acc: 0.9634 - val_loss: -0.9609 - val_acc: 0.9605\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9643 - acc: 0.9652 - val_loss: -0.9629 - val_acc: 0.9594\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9652 - acc: 0.9661 - val_loss: -0.9589 - val_acc: 0.9562\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9665 - acc: 0.9688 - val_loss: -0.9639 - val_acc: 0.9615\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9665 - acc: 0.9664 - val_loss: -0.9562 - val_acc: 0.9476\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9684 - acc: 0.9700 - val_loss: -0.9647 - val_acc: 0.9626\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9730 - acc: 0.9766 - val_loss: -0.9659 - val_acc: 0.9594\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9755 - acc: 0.9784 - val_loss: -0.9641 - val_acc: 0.9605\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9758 - acc: 0.9781 - val_loss: -0.9563 - val_acc: 0.9551\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9583 - acc: 0.9537 - val_loss: -0.9647 - val_acc: 0.9637\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9773 - acc: 0.9793 - val_loss: -0.9704 - val_acc: 0.9712\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9778 - acc: 0.9790 - val_loss: -0.9719 - val_acc: 0.9712\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9787 - acc: 0.9802 - val_loss: -0.9676 - val_acc: 0.9722\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9811 - acc: 0.9853 - val_loss: -0.9723 - val_acc: 0.9701\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9808 - acc: 0.9835 - val_loss: -0.9684 - val_acc: 0.9658\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9751 - acc: 0.9757 - val_loss: -0.9737 - val_acc: 0.9701\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9792 - acc: 0.9805 - val_loss: -0.9695 - val_acc: 0.9647\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9828 - acc: 0.9847 - val_loss: -0.9683 - val_acc: 0.9626\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9828 - acc: 0.9844 - val_loss: -0.9753 - val_acc: 0.9744\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9843 - acc: 0.9859 - val_loss: -0.9744 - val_acc: 0.9712\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9854 - acc: 0.9880 - val_loss: -0.9735 - val_acc: 0.9712\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9864 - acc: 0.9895 - val_loss: -0.9770 - val_acc: 0.9754\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9877 - acc: 0.9898 - val_loss: -0.9767 - val_acc: 0.9754\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9853 - acc: 0.9883 - val_loss: -0.9748 - val_acc: 0.9712\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9862 - acc: 0.9892 - val_loss: -0.9764 - val_acc: 0.9722\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9865 - acc: 0.9889 - val_loss: -0.9737 - val_acc: 0.9722\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9813 - acc: 0.9826 - val_loss: -0.9780 - val_acc: 0.9808\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9788 - acc: 0.9787 - val_loss: -0.9780 - val_acc: 0.9765\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in [keras.optimizers.Adadelta(), keras.optimizers.Adagrad(),\n",
    "          keras.optimizers.RMSprop(lr=0.001), keras.optimizers.RMSprop(lr=0.002),\n",
    "          keras.optimizers.SGD(lr=0.01), keras.optimizers.SGD(lr=0.02),\n",
    "          keras.optimizers.Nadam(), keras.optimizers.Adamax()\n",
    "         ]:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.cosine_proximity,\n",
    "                    optimizer=i,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['optimizer', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.optimizers.Adadelta object at 0x7fa36ce...</td>\n",
       "      <td>0.872334</td>\n",
       "      <td>0.849359</td>\n",
       "      <td>0.831377</td>\n",
       "      <td>29.503359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.optimizers.Adagrad object at 0x7fa36ce3...</td>\n",
       "      <td>0.995494</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969050</td>\n",
       "      <td>20.075749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.optimizers.RMSprop object at 0x7fa36ce3...</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>0.979701</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>20.731403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.optimizers.RMSprop object at 0x7fa36ce3...</td>\n",
       "      <td>0.995795</td>\n",
       "      <td>0.962607</td>\n",
       "      <td>0.960512</td>\n",
       "      <td>20.936719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.optimizers.SGD object at 0x7fa36ce32400&gt;</td>\n",
       "      <td>0.725143</td>\n",
       "      <td>0.704060</td>\n",
       "      <td>0.703308</td>\n",
       "      <td>20.261232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.optimizers.SGD object at 0x7fa36ce32358&gt;</td>\n",
       "      <td>0.409132</td>\n",
       "      <td>0.394231</td>\n",
       "      <td>0.409819</td>\n",
       "      <td>19.518373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.optimizers.Nadam object at 0x7fa36ce32c18&gt;</td>\n",
       "      <td>0.998198</td>\n",
       "      <td>0.969017</td>\n",
       "      <td>0.970117</td>\n",
       "      <td>23.997826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.optimizers.Adamax object at 0x7fa36ce32...</td>\n",
       "      <td>0.996696</td>\n",
       "      <td>0.976496</td>\n",
       "      <td>0.976521</td>\n",
       "      <td>21.380894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           optimizer  training_accuracy  \\\n",
       "0  <keras.optimizers.Adadelta object at 0x7fa36ce...           0.872334   \n",
       "1  <keras.optimizers.Adagrad object at 0x7fa36ce3...           0.995494   \n",
       "2  <keras.optimizers.RMSprop object at 0x7fa36ce3...           0.999099   \n",
       "3  <keras.optimizers.RMSprop object at 0x7fa36ce3...           0.995795   \n",
       "4    <keras.optimizers.SGD object at 0x7fa36ce32400>           0.725143   \n",
       "5    <keras.optimizers.SGD object at 0x7fa36ce32358>           0.409132   \n",
       "6  <keras.optimizers.Nadam object at 0x7fa36ce32c18>           0.998198   \n",
       "7  <keras.optimizers.Adamax object at 0x7fa36ce32...           0.996696   \n",
       "\n",
       "   validation_accuracy  test_accuracy   run_time  \n",
       "0             0.849359       0.831377  29.503359  \n",
       "1             0.974359       0.969050  20.075749  \n",
       "2             0.979701       0.976521  20.731403  \n",
       "3             0.962607       0.960512  20.936719  \n",
       "4             0.704060       0.703308  20.261232  \n",
       "5             0.394231       0.409819  19.518373  \n",
       "6             0.969017       0.970117  23.997826  \n",
       "7             0.976496       0.976521  21.380894  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 473us/step - loss: -0.5683 - acc: 0.4803 - val_loss: -0.6650 - val_acc: 0.6303\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.6747 - acc: 0.6149 - val_loss: -0.7203 - val_acc: 0.6720\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.7403 - acc: 0.7005 - val_loss: -0.7922 - val_acc: 0.7543\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.7755 - acc: 0.7453 - val_loss: -0.7895 - val_acc: 0.8088\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.8041 - acc: 0.7771 - val_loss: -0.8215 - val_acc: 0.8109\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8276 - acc: 0.8084 - val_loss: -0.8526 - val_acc: 0.8280\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.8553 - acc: 0.8426 - val_loss: -0.8763 - val_acc: 0.8547\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.8676 - acc: 0.8567 - val_loss: -0.8751 - val_acc: 0.8643\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.8863 - acc: 0.8831 - val_loss: -0.8971 - val_acc: 0.8868\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.8953 - acc: 0.8916 - val_loss: -0.9046 - val_acc: 0.9017\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9005 - acc: 0.8931 - val_loss: -0.9133 - val_acc: 0.9103\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9091 - acc: 0.9012 - val_loss: -0.8989 - val_acc: 0.8996\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9105 - acc: 0.9057 - val_loss: -0.9281 - val_acc: 0.9188\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9167 - acc: 0.9141 - val_loss: -0.9286 - val_acc: 0.9284\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9292 - acc: 0.9294 - val_loss: -0.9384 - val_acc: 0.9370\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9327 - acc: 0.9327 - val_loss: -0.9327 - val_acc: 0.9274\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9343 - acc: 0.9348 - val_loss: -0.9419 - val_acc: 0.9434\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9409 - acc: 0.9426 - val_loss: -0.9448 - val_acc: 0.9391\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9426 - acc: 0.9468 - val_loss: -0.9441 - val_acc: 0.9391\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9419 - acc: 0.9423 - val_loss: -0.9385 - val_acc: 0.9327\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9489 - acc: 0.9510 - val_loss: -0.9452 - val_acc: 0.9412\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9502 - acc: 0.9531 - val_loss: -0.9540 - val_acc: 0.9519\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9539 - acc: 0.9546 - val_loss: -0.9530 - val_acc: 0.9541\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9537 - acc: 0.9561 - val_loss: -0.9586 - val_acc: 0.9530\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.9590 - acc: 0.9631 - val_loss: -0.9566 - val_acc: 0.9519\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9613 - acc: 0.9631 - val_loss: -0.9608 - val_acc: 0.9658\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9535 - acc: 0.9531 - val_loss: -0.9616 - val_acc: 0.9615\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9642 - acc: 0.9673 - val_loss: -0.9633 - val_acc: 0.9615\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9641 - acc: 0.9691 - val_loss: -0.9652 - val_acc: 0.9679\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9687 - acc: 0.9724 - val_loss: -0.9635 - val_acc: 0.9615\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9674 - acc: 0.9676 - val_loss: -0.9667 - val_acc: 0.9690\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9703 - acc: 0.9730 - val_loss: -0.9672 - val_acc: 0.9679\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9695 - acc: 0.9730 - val_loss: -0.9678 - val_acc: 0.9615\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9685 - acc: 0.9730 - val_loss: -0.9693 - val_acc: 0.9690\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9725 - acc: 0.9757 - val_loss: -0.9710 - val_acc: 0.9722\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9742 - acc: 0.9754 - val_loss: -0.9695 - val_acc: 0.9701\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9762 - acc: 0.9775 - val_loss: -0.9752 - val_acc: 0.9776\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9787 - acc: 0.9814 - val_loss: -0.9730 - val_acc: 0.9754\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9797 - acc: 0.9820 - val_loss: -0.9752 - val_acc: 0.9786\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9785 - acc: 0.9805 - val_loss: -0.9691 - val_acc: 0.9744\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9770 - acc: 0.9814 - val_loss: -0.9734 - val_acc: 0.9776\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9761 - acc: 0.9790 - val_loss: -0.9769 - val_acc: 0.9808\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9820 - acc: 0.9859 - val_loss: -0.9764 - val_acc: 0.9776\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9820 - acc: 0.9841 - val_loss: -0.9784 - val_acc: 0.9765\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9832 - acc: 0.9856 - val_loss: -0.9772 - val_acc: 0.9786\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9843 - acc: 0.9883 - val_loss: -0.9769 - val_acc: 0.9722\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9820 - acc: 0.9841 - val_loss: -0.9712 - val_acc: 0.9733\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9849 - acc: 0.9868 - val_loss: -0.9789 - val_acc: 0.9754\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9842 - acc: 0.9865 - val_loss: -0.9772 - val_acc: 0.9776\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9863 - acc: 0.9889 - val_loss: -0.9760 - val_acc: 0.9786\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 489us/step - loss: -0.5931 - acc: 0.4881 - val_loss: -0.7200 - val_acc: 0.6699\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.7340 - acc: 0.6912 - val_loss: -0.7753 - val_acc: 0.7682\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.7909 - acc: 0.7630 - val_loss: -0.8078 - val_acc: 0.7938\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.8195 - acc: 0.7912 - val_loss: -0.8595 - val_acc: 0.8472\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.8584 - acc: 0.8462 - val_loss: -0.8758 - val_acc: 0.8643\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8752 - acc: 0.8678 - val_loss: -0.8627 - val_acc: 0.8397\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.8878 - acc: 0.8786 - val_loss: -0.9002 - val_acc: 0.8942\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8996 - acc: 0.8952 - val_loss: -0.9042 - val_acc: 0.8910\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9137 - acc: 0.9129 - val_loss: -0.9235 - val_acc: 0.9177\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9183 - acc: 0.9123 - val_loss: -0.9265 - val_acc: 0.9220\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9191 - acc: 0.9153 - val_loss: -0.9368 - val_acc: 0.9380\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9342 - acc: 0.9324 - val_loss: -0.9329 - val_acc: 0.9241\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9215 - acc: 0.9177 - val_loss: -0.9385 - val_acc: 0.9391\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9476 - acc: 0.9480 - val_loss: -0.9484 - val_acc: 0.9487\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9517 - acc: 0.9537 - val_loss: -0.9301 - val_acc: 0.9220\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9425 - acc: 0.9390 - val_loss: -0.9506 - val_acc: 0.9476\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9568 - acc: 0.9573 - val_loss: -0.9516 - val_acc: 0.9466\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9617 - acc: 0.9652 - val_loss: -0.9555 - val_acc: 0.9541\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9647 - acc: 0.9679 - val_loss: -0.9605 - val_acc: 0.9594\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9660 - acc: 0.9688 - val_loss: -0.9615 - val_acc: 0.9541\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9668 - acc: 0.9715 - val_loss: -0.9640 - val_acc: 0.9615\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9690 - acc: 0.9727 - val_loss: -0.9660 - val_acc: 0.9669\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9725 - acc: 0.9754 - val_loss: -0.9658 - val_acc: 0.9615\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9727 - acc: 0.9742 - val_loss: -0.9650 - val_acc: 0.9626\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9729 - acc: 0.9742 - val_loss: -0.9674 - val_acc: 0.9615\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9744 - acc: 0.9784 - val_loss: -0.9669 - val_acc: 0.9637\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9742 - acc: 0.9748 - val_loss: -0.9686 - val_acc: 0.9647\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9792 - acc: 0.9829 - val_loss: -0.9696 - val_acc: 0.9669\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9766 - acc: 0.9772 - val_loss: -0.9697 - val_acc: 0.9722\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9793 - acc: 0.9802 - val_loss: -0.9721 - val_acc: 0.9712\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9813 - acc: 0.9841 - val_loss: -0.9733 - val_acc: 0.9744\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9833 - acc: 0.9850 - val_loss: -0.9723 - val_acc: 0.9733\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9825 - acc: 0.9847 - val_loss: -0.9742 - val_acc: 0.9722\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9829 - acc: 0.9862 - val_loss: -0.9752 - val_acc: 0.9722\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9850 - acc: 0.9880 - val_loss: -0.9729 - val_acc: 0.9701\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9870 - acc: 0.9898 - val_loss: -0.9775 - val_acc: 0.9776\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9853 - acc: 0.9859 - val_loss: -0.9734 - val_acc: 0.9722\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9863 - acc: 0.9886 - val_loss: -0.9771 - val_acc: 0.9786\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9856 - acc: 0.9877 - val_loss: -0.9736 - val_acc: 0.9722\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9879 - acc: 0.9892 - val_loss: -0.9765 - val_acc: 0.9754\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9871 - acc: 0.9880 - val_loss: -0.9752 - val_acc: 0.9733\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9784 - acc: 0.9778 - val_loss: -0.9765 - val_acc: 0.9744\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9884 - acc: 0.9919 - val_loss: -0.9794 - val_acc: 0.9765\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9809 - acc: 0.9811 - val_loss: -0.9750 - val_acc: 0.9733\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9879 - acc: 0.9904 - val_loss: -0.9799 - val_acc: 0.9776\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9869 - acc: 0.9880 - val_loss: -0.9807 - val_acc: 0.9786\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9923 - acc: 0.9949 - val_loss: -0.9788 - val_acc: 0.9754\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9910 - acc: 0.9934 - val_loss: -0.9751 - val_acc: 0.9733\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9905 - acc: 0.9922 - val_loss: -0.9780 - val_acc: 0.9733\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9798 - acc: 0.9796 - val_loss: -0.9791 - val_acc: 0.9733\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 487us/step - loss: -0.5951 - acc: 0.4920 - val_loss: -0.7072 - val_acc: 0.7030\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.7294 - acc: 0.6840 - val_loss: -0.7695 - val_acc: 0.7276\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.7766 - acc: 0.7444 - val_loss: -0.8059 - val_acc: 0.7735\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.8079 - acc: 0.7756 - val_loss: -0.8327 - val_acc: 0.8034\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.8281 - acc: 0.8105 - val_loss: -0.8458 - val_acc: 0.8205\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.8442 - acc: 0.8213 - val_loss: -0.8623 - val_acc: 0.8397\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.8595 - acc: 0.8453 - val_loss: -0.8833 - val_acc: 0.8771\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.8746 - acc: 0.8636 - val_loss: -0.8744 - val_acc: 0.8665\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.8766 - acc: 0.8648 - val_loss: -0.9043 - val_acc: 0.8900\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8857 - acc: 0.8777 - val_loss: -0.9126 - val_acc: 0.9092\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9087 - acc: 0.9018 - val_loss: -0.9255 - val_acc: 0.9209\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9182 - acc: 0.9153 - val_loss: -0.9286 - val_acc: 0.9295\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9262 - acc: 0.9228 - val_loss: -0.9330 - val_acc: 0.9444\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9267 - acc: 0.9267 - val_loss: -0.9340 - val_acc: 0.9380\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9306 - acc: 0.9285 - val_loss: -0.9297 - val_acc: 0.9241\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9335 - acc: 0.9345 - val_loss: -0.9352 - val_acc: 0.9359\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9367 - acc: 0.9351 - val_loss: -0.9383 - val_acc: 0.9402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9439 - acc: 0.9417 - val_loss: -0.9334 - val_acc: 0.9231\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9422 - acc: 0.9411 - val_loss: -0.9512 - val_acc: 0.9487\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9501 - acc: 0.9489 - val_loss: -0.9469 - val_acc: 0.9391\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9554 - acc: 0.9570 - val_loss: -0.9496 - val_acc: 0.9455\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9500 - acc: 0.9510 - val_loss: -0.9101 - val_acc: 0.9006\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9537 - acc: 0.9546 - val_loss: -0.9559 - val_acc: 0.9551\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9589 - acc: 0.9561 - val_loss: -0.9574 - val_acc: 0.9562\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9545 - acc: 0.9549 - val_loss: -0.9502 - val_acc: 0.9476\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9600 - acc: 0.9603 - val_loss: -0.9638 - val_acc: 0.9626\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9646 - acc: 0.9646 - val_loss: -0.9423 - val_acc: 0.9316\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9534 - acc: 0.9501 - val_loss: -0.9564 - val_acc: 0.9476\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9702 - acc: 0.9709 - val_loss: -0.9579 - val_acc: 0.9551\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9714 - acc: 0.9718 - val_loss: -0.9592 - val_acc: 0.9562\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9698 - acc: 0.9712 - val_loss: -0.9700 - val_acc: 0.9658\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9731 - acc: 0.9760 - val_loss: -0.9674 - val_acc: 0.9690\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9782 - acc: 0.9799 - val_loss: -0.9717 - val_acc: 0.9669\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 122us/step - loss: -0.9745 - acc: 0.9721 - val_loss: -0.9693 - val_acc: 0.9658\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9763 - acc: 0.9760 - val_loss: -0.9714 - val_acc: 0.9690\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9768 - acc: 0.9790 - val_loss: -0.9728 - val_acc: 0.9733\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9741 - acc: 0.9736 - val_loss: -0.9681 - val_acc: 0.9637\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9753 - acc: 0.9778 - val_loss: -0.9756 - val_acc: 0.9776\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9793 - acc: 0.9811 - val_loss: -0.9720 - val_acc: 0.9669\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9789 - acc: 0.9796 - val_loss: -0.9743 - val_acc: 0.9765\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9817 - acc: 0.9829 - val_loss: -0.9705 - val_acc: 0.9637\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 120us/step - loss: -0.9778 - acc: 0.9760 - val_loss: -0.9712 - val_acc: 0.9701\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9779 - acc: 0.9796 - val_loss: -0.9761 - val_acc: 0.9733\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9790 - acc: 0.9799 - val_loss: -0.9748 - val_acc: 0.9712\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9820 - acc: 0.9832 - val_loss: -0.9784 - val_acc: 0.9765\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9814 - acc: 0.9817 - val_loss: -0.9542 - val_acc: 0.9476\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 121us/step - loss: -0.9841 - acc: 0.9853 - val_loss: -0.9810 - val_acc: 0.9808\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 119us/step - loss: -0.9820 - acc: 0.9817 - val_loss: -0.9784 - val_acc: 0.9776\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9828 - acc: 0.9841 - val_loss: -0.9798 - val_acc: 0.9797\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9799 - acc: 0.9808 - val_loss: -0.9723 - val_acc: 0.9701\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 537us/step - loss: -0.6098 - acc: 0.5140 - val_loss: -0.6653 - val_acc: 0.6111\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.7123 - acc: 0.6600 - val_loss: -0.7525 - val_acc: 0.6998\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.7538 - acc: 0.7137 - val_loss: -0.7741 - val_acc: 0.7564\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.7787 - acc: 0.7342 - val_loss: -0.7996 - val_acc: 0.7767\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.7924 - acc: 0.7579 - val_loss: -0.7749 - val_acc: 0.7169\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.8143 - acc: 0.7837 - val_loss: -0.8396 - val_acc: 0.8066\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.8338 - acc: 0.8038 - val_loss: -0.7602 - val_acc: 0.7062\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.8296 - acc: 0.7993 - val_loss: -0.8355 - val_acc: 0.8109\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.8586 - acc: 0.8399 - val_loss: -0.8636 - val_acc: 0.8397\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.8586 - acc: 0.8411 - val_loss: -0.8651 - val_acc: 0.8462\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.8696 - acc: 0.8552 - val_loss: -0.8531 - val_acc: 0.8280\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.8789 - acc: 0.8645 - val_loss: -0.9061 - val_acc: 0.9028\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9024 - acc: 0.8964 - val_loss: -0.9132 - val_acc: 0.9038\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9080 - acc: 0.9030 - val_loss: -0.8970 - val_acc: 0.8889\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9084 - acc: 0.8982 - val_loss: -0.9053 - val_acc: 0.8900\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9158 - acc: 0.9090 - val_loss: -0.9112 - val_acc: 0.8996\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9193 - acc: 0.9129 - val_loss: -0.9268 - val_acc: 0.9263\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.9175 - acc: 0.9096 - val_loss: -0.9195 - val_acc: 0.9060\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.9149 - acc: 0.9105 - val_loss: -0.9320 - val_acc: 0.9220\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9348 - acc: 0.9330 - val_loss: -0.9414 - val_acc: 0.9370\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.9386 - acc: 0.9357 - val_loss: -0.9379 - val_acc: 0.9316\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.9406 - acc: 0.9363 - val_loss: -0.9461 - val_acc: 0.9412\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 108us/step - loss: -0.9462 - acc: 0.9444 - val_loss: -0.9361 - val_acc: 0.9263\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9314 - acc: 0.9201 - val_loss: -0.9468 - val_acc: 0.9476\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9506 - acc: 0.9498 - val_loss: -0.9438 - val_acc: 0.9370\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9424 - acc: 0.9357 - val_loss: -0.9534 - val_acc: 0.9573\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9573 - acc: 0.9567 - val_loss: -0.9506 - val_acc: 0.9476\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 118us/step - loss: -0.9596 - acc: 0.9579 - val_loss: -0.9604 - val_acc: 0.9573\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9630 - acc: 0.9649 - val_loss: -0.9635 - val_acc: 0.9637\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 117us/step - loss: -0.9647 - acc: 0.9658 - val_loss: -0.9616 - val_acc: 0.9626\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9675 - acc: 0.9670 - val_loss: -0.9621 - val_acc: 0.9583\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9677 - acc: 0.9700 - val_loss: -0.9649 - val_acc: 0.9647\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9661 - acc: 0.9658 - val_loss: -0.9612 - val_acc: 0.9583\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9687 - acc: 0.9715 - val_loss: -0.9497 - val_acc: 0.9487\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9663 - acc: 0.9664 - val_loss: -0.9358 - val_acc: 0.9284\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9376 - acc: 0.9291 - val_loss: -0.9617 - val_acc: 0.9551\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 109us/step - loss: -0.9712 - acc: 0.9724 - val_loss: -0.9632 - val_acc: 0.9594\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.9714 - acc: 0.9706 - val_loss: -0.9705 - val_acc: 0.9669\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 106us/step - loss: -0.9765 - acc: 0.9787 - val_loss: -0.9646 - val_acc: 0.9626\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9731 - acc: 0.9739 - val_loss: -0.9704 - val_acc: 0.9647\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 114us/step - loss: -0.9792 - acc: 0.9823 - val_loss: -0.9679 - val_acc: 0.9637\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9770 - acc: 0.9769 - val_loss: -0.9727 - val_acc: 0.9712\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9809 - acc: 0.9832 - val_loss: -0.9692 - val_acc: 0.9637\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 112us/step - loss: -0.9791 - acc: 0.9805 - val_loss: -0.9710 - val_acc: 0.9679\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 110us/step - loss: -0.9793 - acc: 0.9787 - val_loss: -0.9707 - val_acc: 0.9679\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 115us/step - loss: -0.9805 - acc: 0.9838 - val_loss: -0.9709 - val_acc: 0.9679\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 116us/step - loss: -0.9776 - acc: 0.9796 - val_loss: -0.9732 - val_acc: 0.9712\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 111us/step - loss: -0.9782 - acc: 0.9784 - val_loss: -0.9737 - val_acc: 0.9669\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9792 - acc: 0.9799 - val_loss: -0.9679 - val_acc: 0.9658\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 113us/step - loss: -0.9798 - acc: 0.9814 - val_loss: -0.9673 - val_acc: 0.9626\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in [1, 3, 5, 7]:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(i, i),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.cosine_proximity,\n",
    "                    optimizer=keras.optimizers.Adamax(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['kernel_size', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.994293</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.980790</td>\n",
       "      <td>23.330324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.997597</td>\n",
       "      <td>0.973291</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>22.536363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.990688</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.960512</td>\n",
       "      <td>22.502177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.991589</td>\n",
       "      <td>0.962607</td>\n",
       "      <td>0.957311</td>\n",
       "      <td>21.032849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   optimizer  training_accuracy  validation_accuracy  test_accuracy   run_time\n",
       "0          1           0.994293             0.978632       0.980790  23.330324\n",
       "1          3           0.997597             0.973291       0.974386  22.536363\n",
       "2          5           0.990688             0.970085       0.960512  22.502177\n",
       "3          7           0.991589             0.962607       0.957311  21.032849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 566us/step - loss: -0.5906 - acc: 0.5125 - val_loss: -0.6893 - val_acc: 0.6496\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 140us/step - loss: -0.7076 - acc: 0.6663 - val_loss: -0.7529 - val_acc: 0.6976\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.7677 - acc: 0.7390 - val_loss: -0.8086 - val_acc: 0.8056\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.7941 - acc: 0.7630 - val_loss: -0.8394 - val_acc: 0.8162\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.8336 - acc: 0.8192 - val_loss: -0.8538 - val_acc: 0.8643\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.8581 - acc: 0.8510 - val_loss: -0.8701 - val_acc: 0.8590\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.8595 - acc: 0.8555 - val_loss: -0.8905 - val_acc: 0.8868\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.8873 - acc: 0.8810 - val_loss: -0.8580 - val_acc: 0.8419\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.8599 - acc: 0.8456 - val_loss: -0.9045 - val_acc: 0.9124\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8985 - acc: 0.8979 - val_loss: -0.9059 - val_acc: 0.9017\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9093 - acc: 0.9054 - val_loss: -0.9085 - val_acc: 0.9209\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9140 - acc: 0.9120 - val_loss: -0.9221 - val_acc: 0.9231\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9229 - acc: 0.9228 - val_loss: -0.9153 - val_acc: 0.9124\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9182 - acc: 0.9165 - val_loss: -0.9007 - val_acc: 0.8953\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9125 - acc: 0.9069 - val_loss: -0.9314 - val_acc: 0.9391\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9347 - acc: 0.9366 - val_loss: -0.9355 - val_acc: 0.9338\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9400 - acc: 0.9462 - val_loss: -0.9400 - val_acc: 0.9434\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9441 - acc: 0.9483 - val_loss: -0.9450 - val_acc: 0.9391\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9456 - acc: 0.9453 - val_loss: -0.9439 - val_acc: 0.9476\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9489 - acc: 0.9528 - val_loss: -0.9470 - val_acc: 0.9487\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9557 - acc: 0.9600 - val_loss: -0.9509 - val_acc: 0.9573\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9518 - acc: 0.9534 - val_loss: -0.9511 - val_acc: 0.9509\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9559 - acc: 0.9600 - val_loss: -0.9461 - val_acc: 0.9423\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9547 - acc: 0.9591 - val_loss: -0.9465 - val_acc: 0.9423\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9585 - acc: 0.9628 - val_loss: -0.9522 - val_acc: 0.9509\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9607 - acc: 0.9640 - val_loss: -0.9537 - val_acc: 0.9509\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.9622 - acc: 0.9670 - val_loss: -0.9478 - val_acc: 0.9455\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9537 - acc: 0.9546 - val_loss: -0.9581 - val_acc: 0.9541\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9642 - acc: 0.9670 - val_loss: -0.9592 - val_acc: 0.9530\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9663 - acc: 0.9652 - val_loss: -0.9390 - val_acc: 0.9327\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9572 - acc: 0.9582 - val_loss: -0.9603 - val_acc: 0.9615\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9661 - acc: 0.9667 - val_loss: -0.9617 - val_acc: 0.9605\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9714 - acc: 0.9757 - val_loss: -0.9649 - val_acc: 0.9690\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9545 - acc: 0.9525 - val_loss: -0.9621 - val_acc: 0.9637\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9714 - acc: 0.9736 - val_loss: -0.9677 - val_acc: 0.9679\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9780 - acc: 0.9832 - val_loss: -0.9655 - val_acc: 0.9647\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9778 - acc: 0.9829 - val_loss: -0.9686 - val_acc: 0.9701\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9774 - acc: 0.9793 - val_loss: -0.9631 - val_acc: 0.9605\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9780 - acc: 0.9832 - val_loss: -0.9701 - val_acc: 0.9733\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9758 - acc: 0.9763 - val_loss: -0.9646 - val_acc: 0.9573\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9799 - acc: 0.9829 - val_loss: -0.9682 - val_acc: 0.9626\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9820 - acc: 0.9850 - val_loss: -0.9743 - val_acc: 0.9765\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9821 - acc: 0.9832 - val_loss: -0.9681 - val_acc: 0.9679\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9813 - acc: 0.9832 - val_loss: -0.9737 - val_acc: 0.9733\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9812 - acc: 0.9826 - val_loss: -0.9649 - val_acc: 0.9573\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9828 - acc: 0.9862 - val_loss: -0.9719 - val_acc: 0.9733\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9838 - acc: 0.9862 - val_loss: -0.9690 - val_acc: 0.9669\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 123us/step - loss: -0.9806 - acc: 0.9844 - val_loss: -0.9719 - val_acc: 0.9744\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9843 - acc: 0.9895 - val_loss: -0.9711 - val_acc: 0.9669\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 124us/step - loss: -0.9831 - acc: 0.9865 - val_loss: -0.9753 - val_acc: 0.9765\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 579us/step - loss: -0.4695 - acc: 0.4584 - val_loss: -0.5126 - val_acc: 0.5107\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 1s 151us/step - loss: -0.5094 - acc: 0.5047 - val_loss: -0.5628 - val_acc: 0.5310\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 149us/step - loss: -0.5114 - acc: 0.5032 - val_loss: -0.5234 - val_acc: 0.5235\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 143us/step - loss: -0.5105 - acc: 0.5083 - val_loss: -0.5276 - val_acc: 0.5267\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 144us/step - loss: -0.5699 - acc: 0.5533 - val_loss: -0.6606 - val_acc: 0.6175\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 145us/step - loss: -0.6491 - acc: 0.6227 - val_loss: -0.6957 - val_acc: 0.6709\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 148us/step - loss: -0.6974 - acc: 0.6669 - val_loss: -0.7412 - val_acc: 0.7179\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 145us/step - loss: -0.7596 - acc: 0.7296 - val_loss: -0.7795 - val_acc: 0.7596\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 150us/step - loss: -0.7923 - acc: 0.7621 - val_loss: -0.8240 - val_acc: 0.8013\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 1s 150us/step - loss: -0.8093 - acc: 0.7846 - val_loss: -0.8230 - val_acc: 0.7949\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 146us/step - loss: -0.8051 - acc: 0.7744 - val_loss: -0.8209 - val_acc: 0.8002\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 143us/step - loss: -0.8482 - acc: 0.8306 - val_loss: -0.8386 - val_acc: 0.8194\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 141us/step - loss: -0.8406 - acc: 0.8219 - val_loss: -0.8656 - val_acc: 0.8579\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 146us/step - loss: -0.8606 - acc: 0.8462 - val_loss: -0.8693 - val_acc: 0.8558\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 143us/step - loss: -0.8676 - acc: 0.8570 - val_loss: -0.8407 - val_acc: 0.8173\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 150us/step - loss: -0.8704 - acc: 0.8594 - val_loss: -0.8528 - val_acc: 0.8397\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 149us/step - loss: -0.8811 - acc: 0.8720 - val_loss: -0.8558 - val_acc: 0.8419\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 1s 153us/step - loss: -0.8807 - acc: 0.8702 - val_loss: -0.8717 - val_acc: 0.8590\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 1s 153us/step - loss: -0.8872 - acc: 0.8804 - val_loss: -0.8790 - val_acc: 0.8675\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 1s 154us/step - loss: -0.8865 - acc: 0.8795 - val_loss: -0.8903 - val_acc: 0.8814\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 147us/step - loss: -0.8905 - acc: 0.8813 - val_loss: -0.8811 - val_acc: 0.8718\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 1s 151us/step - loss: -0.8971 - acc: 0.8901 - val_loss: -0.8923 - val_acc: 0.8835\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 1s 152us/step - loss: -0.8972 - acc: 0.8919 - val_loss: -0.8651 - val_acc: 0.8536\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 1s 151us/step - loss: -0.8939 - acc: 0.8831 - val_loss: -0.8653 - val_acc: 0.8472\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 1s 155us/step - loss: -0.8966 - acc: 0.8892 - val_loss: -0.8964 - val_acc: 0.8857\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 147us/step - loss: -0.8969 - acc: 0.8840 - val_loss: -0.8896 - val_acc: 0.8835\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 147us/step - loss: -0.9112 - acc: 0.9036 - val_loss: -0.9041 - val_acc: 0.8964\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 147us/step - loss: -0.9146 - acc: 0.9081 - val_loss: -0.9063 - val_acc: 0.8974\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 150us/step - loss: -0.9190 - acc: 0.9153 - val_loss: -0.9108 - val_acc: 0.9081\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 149us/step - loss: -0.9238 - acc: 0.9213 - val_loss: -0.9020 - val_acc: 0.8964\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 148us/step - loss: -0.9192 - acc: 0.9123 - val_loss: -0.9100 - val_acc: 0.9028\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 142us/step - loss: -0.9267 - acc: 0.9228 - val_loss: -0.9110 - val_acc: 0.9017\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 143us/step - loss: -0.9248 - acc: 0.9198 - val_loss: -0.9133 - val_acc: 0.9049\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 146us/step - loss: -0.9295 - acc: 0.9258 - val_loss: -0.9117 - val_acc: 0.9038\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 141us/step - loss: -0.9275 - acc: 0.9237 - val_loss: -0.9163 - val_acc: 0.9113\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 142us/step - loss: -0.9278 - acc: 0.9222 - val_loss: -0.9157 - val_acc: 0.9135\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 143us/step - loss: -0.9333 - acc: 0.9315 - val_loss: -0.9206 - val_acc: 0.9103\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 148us/step - loss: -0.9348 - acc: 0.9315 - val_loss: -0.9164 - val_acc: 0.9113\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 144us/step - loss: -0.9343 - acc: 0.9285 - val_loss: -0.9123 - val_acc: 0.9006\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 147us/step - loss: -0.9375 - acc: 0.9354 - val_loss: -0.9126 - val_acc: 0.9017\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 1s 152us/step - loss: -0.9335 - acc: 0.9303 - val_loss: -0.9228 - val_acc: 0.9209\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 147us/step - loss: -0.9389 - acc: 0.9375 - val_loss: -0.9103 - val_acc: 0.9028\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 144us/step - loss: -0.9368 - acc: 0.9318 - val_loss: -0.9176 - val_acc: 0.9071\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 1s 151us/step - loss: -0.9292 - acc: 0.9240 - val_loss: -0.9171 - val_acc: 0.9060\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 1s 154us/step - loss: -0.9356 - acc: 0.9327 - val_loss: -0.9095 - val_acc: 0.9006\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 1s 153us/step - loss: -0.9403 - acc: 0.9363 - val_loss: -0.8604 - val_acc: 0.8269\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 1s 154us/step - loss: -0.9331 - acc: 0.9273 - val_loss: -0.9074 - val_acc: 0.8974\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 149us/step - loss: -0.9332 - acc: 0.9300 - val_loss: -0.9111 - val_acc: 0.9038\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 146us/step - loss: -0.9439 - acc: 0.9420 - val_loss: -0.9137 - val_acc: 0.9081\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 142us/step - loss: -0.9409 - acc: 0.9399 - val_loss: -0.9170 - val_acc: 0.9060\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 653us/step - loss: -0.5348 - acc: 0.4884 - val_loss: -0.6069 - val_acc: 0.5662\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.6592 - acc: 0.6170 - val_loss: -0.6906 - val_acc: 0.6560\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.7412 - acc: 0.6984 - val_loss: -0.7985 - val_acc: 0.7511\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.7846 - acc: 0.7510 - val_loss: -0.8230 - val_acc: 0.8024\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.8047 - acc: 0.7756 - val_loss: -0.8454 - val_acc: 0.8194\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.8350 - acc: 0.8162 - val_loss: -0.8485 - val_acc: 0.8269\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.8463 - acc: 0.8204 - val_loss: -0.8616 - val_acc: 0.8483\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.8695 - acc: 0.8558 - val_loss: -0.8501 - val_acc: 0.8312\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.8707 - acc: 0.8513 - val_loss: -0.8478 - val_acc: 0.8301\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.8481 - acc: 0.8288 - val_loss: -0.8877 - val_acc: 0.8750\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.8883 - acc: 0.8747 - val_loss: -0.8900 - val_acc: 0.8825\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8844 - acc: 0.8654 - val_loss: -0.8924 - val_acc: 0.8718\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9002 - acc: 0.8886 - val_loss: -0.8980 - val_acc: 0.8814\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9024 - acc: 0.8925 - val_loss: -0.9071 - val_acc: 0.8953\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9139 - acc: 0.9069 - val_loss: -0.9014 - val_acc: 0.8846\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9045 - acc: 0.8916 - val_loss: -0.9178 - val_acc: 0.9113\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9188 - acc: 0.9138 - val_loss: -0.8846 - val_acc: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9203 - acc: 0.9150 - val_loss: -0.9166 - val_acc: 0.9113\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9290 - acc: 0.9258 - val_loss: -0.9213 - val_acc: 0.9177\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9313 - acc: 0.9288 - val_loss: -0.9223 - val_acc: 0.9092\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9256 - acc: 0.9243 - val_loss: -0.8894 - val_acc: 0.8697\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9217 - acc: 0.9120 - val_loss: -0.9138 - val_acc: 0.9028\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9305 - acc: 0.9237 - val_loss: -0.8864 - val_acc: 0.8547\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 125us/step - loss: -0.9384 - acc: 0.9345 - val_loss: -0.9142 - val_acc: 0.9060\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9405 - acc: 0.9348 - val_loss: -0.9310 - val_acc: 0.9220\n",
      "Epoch 26/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9363 - acc: 0.9282 - val_loss: -0.9150 - val_acc: 0.8974\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9387 - acc: 0.9345 - val_loss: -0.9282 - val_acc: 0.9199\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9452 - acc: 0.9396 - val_loss: -0.9285 - val_acc: 0.9199\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9262 - acc: 0.9162 - val_loss: -0.9343 - val_acc: 0.9359\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9477 - acc: 0.9432 - val_loss: -0.9354 - val_acc: 0.9338\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9531 - acc: 0.9498 - val_loss: -0.9409 - val_acc: 0.9412\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9561 - acc: 0.9531 - val_loss: -0.9295 - val_acc: 0.9156\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9510 - acc: 0.9486 - val_loss: -0.9324 - val_acc: 0.9177\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9565 - acc: 0.9570 - val_loss: -0.9398 - val_acc: 0.9327\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9572 - acc: 0.9534 - val_loss: -0.9224 - val_acc: 0.9081\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9562 - acc: 0.9534 - val_loss: -0.9389 - val_acc: 0.9316\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9602 - acc: 0.9609 - val_loss: -0.9443 - val_acc: 0.9402\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9649 - acc: 0.9667 - val_loss: -0.9407 - val_acc: 0.9370\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.9549 - acc: 0.9510 - val_loss: -0.9436 - val_acc: 0.9370\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.9604 - acc: 0.9579 - val_loss: -0.9427 - val_acc: 0.9402\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9666 - acc: 0.9676 - val_loss: -0.9431 - val_acc: 0.9327\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9664 - acc: 0.9658 - val_loss: -0.9437 - val_acc: 0.9402\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9690 - acc: 0.9697 - val_loss: -0.9448 - val_acc: 0.9402\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9657 - acc: 0.9643 - val_loss: -0.9414 - val_acc: 0.9327\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9672 - acc: 0.9676 - val_loss: -0.9460 - val_acc: 0.9402\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9654 - acc: 0.9643 - val_loss: -0.9321 - val_acc: 0.9252\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9646 - acc: 0.9625 - val_loss: -0.9319 - val_acc: 0.9284\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9615 - acc: 0.9597 - val_loss: -0.9440 - val_acc: 0.9359\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9651 - acc: 0.9625 - val_loss: -0.9494 - val_acc: 0.9466\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9645 - acc: 0.9625 - val_loss: -0.9488 - val_acc: 0.9434\n",
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/50\n",
      "3329/3329 [==============================] - 2s 591us/step - loss: -0.2698 - acc: 0.2064 - val_loss: -0.3044 - val_acc: 0.2265\n",
      "Epoch 2/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.3029 - acc: 0.1986 - val_loss: -0.3501 - val_acc: 0.2265\n",
      "Epoch 3/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.3234 - acc: 0.2088 - val_loss: -0.3940 - val_acc: 0.2265\n",
      "Epoch 4/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.3335 - acc: 0.1950 - val_loss: -0.3915 - val_acc: 0.2265\n",
      "Epoch 5/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.3328 - acc: 0.1968 - val_loss: -0.3957 - val_acc: 0.2265\n",
      "Epoch 6/50\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.3426 - acc: 0.2097 - val_loss: -0.3943 - val_acc: 0.2094\n",
      "Epoch 7/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.3430 - acc: 0.2031 - val_loss: -0.3953 - val_acc: 0.2265\n",
      "Epoch 8/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.3374 - acc: 0.1980 - val_loss: -0.3960 - val_acc: 0.2265\n",
      "Epoch 9/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.3436 - acc: 0.1953 - val_loss: -0.3964 - val_acc: 0.2265\n",
      "Epoch 10/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.3361 - acc: 0.1922 - val_loss: -0.3953 - val_acc: 0.2265\n",
      "Epoch 11/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.3436 - acc: 0.2031 - val_loss: -0.3975 - val_acc: 0.2265\n",
      "Epoch 12/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.3502 - acc: 0.2136 - val_loss: -0.3953 - val_acc: 0.2265\n",
      "Epoch 13/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.3500 - acc: 0.2034 - val_loss: -0.3961 - val_acc: 0.2265\n",
      "Epoch 14/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.3486 - acc: 0.2073 - val_loss: -0.3935 - val_acc: 0.2265\n",
      "Epoch 15/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.3441 - acc: 0.1916 - val_loss: -0.3956 - val_acc: 0.2265\n",
      "Epoch 16/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.3530 - acc: 0.2130 - val_loss: -0.3966 - val_acc: 0.2265\n",
      "Epoch 17/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.3436 - acc: 0.1971 - val_loss: -0.3961 - val_acc: 0.2265\n",
      "Epoch 18/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.3512 - acc: 0.1995 - val_loss: -0.3971 - val_acc: 0.2265\n",
      "Epoch 19/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.3484 - acc: 0.2007 - val_loss: -0.3957 - val_acc: 0.2265\n",
      "Epoch 20/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.3524 - acc: 0.2094 - val_loss: -0.3961 - val_acc: 0.2265\n",
      "Epoch 21/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.3476 - acc: 0.1965 - val_loss: -0.3967 - val_acc: 0.2265\n",
      "Epoch 22/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.3488 - acc: 0.2001 - val_loss: -0.3979 - val_acc: 0.2938\n",
      "Epoch 23/50\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.3601 - acc: 0.2169 - val_loss: -0.4142 - val_acc: 0.3344\n",
      "Epoch 24/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.3696 - acc: 0.2400 - val_loss: -0.4284 - val_acc: 0.3355\n",
      "Epoch 25/50\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.3881 - acc: 0.2634 - val_loss: -0.4356 - val_acc: 0.3494\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.3877 - acc: 0.2604 - val_loss: -0.4414 - val_acc: 0.3419\n",
      "Epoch 27/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.4038 - acc: 0.2836 - val_loss: -0.4494 - val_acc: 0.3643\n",
      "Epoch 28/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.4098 - acc: 0.2980 - val_loss: -0.4599 - val_acc: 0.3782\n",
      "Epoch 29/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.4277 - acc: 0.3058 - val_loss: -0.4941 - val_acc: 0.4145\n",
      "Epoch 30/50\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.4564 - acc: 0.3172 - val_loss: -0.5431 - val_acc: 0.4615\n",
      "Epoch 31/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.4938 - acc: 0.3719 - val_loss: -0.5829 - val_acc: 0.5224\n",
      "Epoch 32/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.5163 - acc: 0.3965 - val_loss: -0.6114 - val_acc: 0.5534\n",
      "Epoch 33/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.5466 - acc: 0.4428 - val_loss: -0.6400 - val_acc: 0.6186\n",
      "Epoch 34/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.5655 - acc: 0.4680 - val_loss: -0.6597 - val_acc: 0.6218\n",
      "Epoch 35/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.5988 - acc: 0.5095 - val_loss: -0.6875 - val_acc: 0.6410\n",
      "Epoch 36/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.6289 - acc: 0.5515 - val_loss: -0.7025 - val_acc: 0.6560\n",
      "Epoch 37/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.6469 - acc: 0.5764 - val_loss: -0.7122 - val_acc: 0.6624\n",
      "Epoch 38/50\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.6621 - acc: 0.5954 - val_loss: -0.7133 - val_acc: 0.6571\n",
      "Epoch 39/50\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.6684 - acc: 0.6035 - val_loss: -0.7276 - val_acc: 0.6731\n",
      "Epoch 40/50\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.6817 - acc: 0.6293 - val_loss: -0.7386 - val_acc: 0.6731\n",
      "Epoch 41/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.6925 - acc: 0.6329 - val_loss: -0.7465 - val_acc: 0.6880\n",
      "Epoch 42/50\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.7038 - acc: 0.6443 - val_loss: -0.7545 - val_acc: 0.6934\n",
      "Epoch 43/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.7004 - acc: 0.6386 - val_loss: -0.7578 - val_acc: 0.7062\n",
      "Epoch 44/50\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.7164 - acc: 0.6657 - val_loss: -0.7653 - val_acc: 0.7105\n",
      "Epoch 45/50\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.7229 - acc: 0.6717 - val_loss: -0.7742 - val_acc: 0.7329\n",
      "Epoch 46/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.7348 - acc: 0.6930 - val_loss: -0.7763 - val_acc: 0.7457\n",
      "Epoch 47/50\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.7373 - acc: 0.6888 - val_loss: -0.7806 - val_acc: 0.7425\n",
      "Epoch 48/50\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.7422 - acc: 0.6990 - val_loss: -0.7900 - val_acc: 0.7639\n",
      "Epoch 49/50\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.7505 - acc: 0.7080 - val_loss: -0.7902 - val_acc: 0.7596\n",
      "Epoch 50/50\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.7521 - acc: 0.7149 - val_loss: -0.8006 - val_acc: 0.7724\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "for i in ['relu', 'selu', 'tanh', 'sigmoid']:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model = Sequential()\n",
    "    # First convolutional layer, note the specification of shape\n",
    "    model.add(Conv2D(32, kernel_size=(1, 1),\n",
    "                        activation='relu',\n",
    "                        input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation=i))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=i))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.cosine_proximity,\n",
    "                    optimizer=keras.optimizers.Adamax(),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    cnn_hist = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=50,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val))\n",
    "    train_score = model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "    val_score = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    test_score = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "    runtime = time.time() - start_time\n",
    "    param_perf.append([i, train_score, val_score, test_score, runtime])\n",
    "    \n",
    "param_perf = pd.DataFrame(param_perf)\n",
    "param_perf.columns = ['kernel_size', 'training_accuracy', 'validation_accuracy', 'test_accuracy', 'run_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.996395</td>\n",
       "      <td>0.976496</td>\n",
       "      <td>0.971185</td>\n",
       "      <td>24.007239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>selu</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.910352</td>\n",
       "      <td>27.097733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.981676</td>\n",
       "      <td>0.943376</td>\n",
       "      <td>0.940235</td>\n",
       "      <td>24.631930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.786723</td>\n",
       "      <td>0.772436</td>\n",
       "      <td>0.756670</td>\n",
       "      <td>24.534674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel_size  training_accuracy  validation_accuracy  test_accuracy  \\\n",
       "0        relu           0.996395             0.976496       0.971185   \n",
       "1        selu           0.948934             0.905983       0.910352   \n",
       "2        tanh           0.981676             0.943376       0.940235   \n",
       "3     sigmoid           0.786723             0.772436       0.756670   \n",
       "\n",
       "    run_time  \n",
       "0  24.007239  \n",
       "1  27.097733  \n",
       "2  24.631930  \n",
       "3  24.534674  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(param_perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X-train-rgb.npy')\n",
    "y_train = np.load('y-train-rgb.npy')\n",
    "X_val = np.load('X-val-rgb.npy')\n",
    "y_val = np.load('y-val-rgb.npy')\n",
    "X_test = np.load('X-test-rgb.npy')\n",
    "y_test = np.load('y-test-rgb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3329 samples, validate on 936 samples\n",
      "Epoch 1/100\n",
      "3329/3329 [==============================] - 2s 645us/step - loss: -0.5593 - acc: 0.4731 - val_loss: -0.6614 - val_acc: 0.6218\n",
      "Epoch 2/100\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.6878 - acc: 0.6461 - val_loss: -0.7346 - val_acc: 0.6699\n",
      "Epoch 3/100\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.7539 - acc: 0.7203 - val_loss: -0.8019 - val_acc: 0.7575\n",
      "Epoch 4/100\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.7879 - acc: 0.7549 - val_loss: -0.8031 - val_acc: 0.7938\n",
      "Epoch 5/100\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.8238 - acc: 0.8053 - val_loss: -0.8451 - val_acc: 0.8472\n",
      "Epoch 6/100\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.8437 - acc: 0.8309 - val_loss: -0.8677 - val_acc: 0.8729\n",
      "Epoch 7/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.8604 - acc: 0.8540 - val_loss: -0.8839 - val_acc: 0.8803\n",
      "Epoch 8/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.8748 - acc: 0.8681 - val_loss: -0.8893 - val_acc: 0.8771\n",
      "Epoch 9/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.8854 - acc: 0.8777 - val_loss: -0.8961 - val_acc: 0.8835\n",
      "Epoch 10/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.8960 - acc: 0.8889 - val_loss: -0.8983 - val_acc: 0.8932\n",
      "Epoch 11/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9047 - acc: 0.9015 - val_loss: -0.9031 - val_acc: 0.8942\n",
      "Epoch 12/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9131 - acc: 0.9126 - val_loss: -0.9272 - val_acc: 0.9252\n",
      "Epoch 13/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9208 - acc: 0.9171 - val_loss: -0.9317 - val_acc: 0.9359\n",
      "Epoch 14/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9258 - acc: 0.9285 - val_loss: -0.9305 - val_acc: 0.9274\n",
      "Epoch 15/100\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.9309 - acc: 0.9303 - val_loss: -0.9413 - val_acc: 0.9391\n",
      "Epoch 16/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9370 - acc: 0.9363 - val_loss: -0.9403 - val_acc: 0.9370\n",
      "Epoch 17/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9404 - acc: 0.9405 - val_loss: -0.9138 - val_acc: 0.9060\n",
      "Epoch 18/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9390 - acc: 0.9408 - val_loss: -0.9379 - val_acc: 0.9327\n",
      "Epoch 19/100\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9452 - acc: 0.9429 - val_loss: -0.9544 - val_acc: 0.9583\n",
      "Epoch 20/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9494 - acc: 0.9501 - val_loss: -0.9483 - val_acc: 0.9466\n",
      "Epoch 21/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9515 - acc: 0.9540 - val_loss: -0.9418 - val_acc: 0.9391\n",
      "Epoch 22/100\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9507 - acc: 0.9495 - val_loss: -0.9141 - val_acc: 0.8953\n",
      "Epoch 23/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9524 - acc: 0.9516 - val_loss: -0.9579 - val_acc: 0.9562\n",
      "Epoch 24/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9517 - acc: 0.9525 - val_loss: -0.9597 - val_acc: 0.9594\n",
      "Epoch 25/100\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9619 - acc: 0.9640 - val_loss: -0.9626 - val_acc: 0.9594\n",
      "Epoch 26/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9673 - acc: 0.9673 - val_loss: -0.9609 - val_acc: 0.9562\n",
      "Epoch 27/100\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9673 - acc: 0.9679 - val_loss: -0.9647 - val_acc: 0.9626\n",
      "Epoch 28/100\n",
      "3329/3329 [==============================] - 0s 129us/step - loss: -0.9691 - acc: 0.9706 - val_loss: -0.9584 - val_acc: 0.9583\n",
      "Epoch 29/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9677 - acc: 0.9700 - val_loss: -0.9636 - val_acc: 0.9605\n",
      "Epoch 30/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9605 - acc: 0.9600 - val_loss: -0.9673 - val_acc: 0.9669\n",
      "Epoch 31/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9728 - acc: 0.9739 - val_loss: -0.9682 - val_acc: 0.9679\n",
      "Epoch 32/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9723 - acc: 0.9736 - val_loss: -0.9680 - val_acc: 0.9669\n",
      "Epoch 33/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9754 - acc: 0.9787 - val_loss: -0.9713 - val_acc: 0.9701\n",
      "Epoch 34/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9783 - acc: 0.9805 - val_loss: -0.9723 - val_acc: 0.9733\n",
      "Epoch 35/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9754 - acc: 0.9736 - val_loss: -0.9735 - val_acc: 0.9712\n",
      "Epoch 36/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9795 - acc: 0.9808 - val_loss: -0.9731 - val_acc: 0.9744\n",
      "Epoch 37/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9781 - acc: 0.9799 - val_loss: -0.9716 - val_acc: 0.9712\n",
      "Epoch 38/100\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.9783 - acc: 0.9796 - val_loss: -0.9722 - val_acc: 0.9744\n",
      "Epoch 39/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9800 - acc: 0.9823 - val_loss: -0.9728 - val_acc: 0.9690\n",
      "Epoch 40/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9810 - acc: 0.9829 - val_loss: -0.9699 - val_acc: 0.9658\n",
      "Epoch 41/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9820 - acc: 0.9853 - val_loss: -0.9736 - val_acc: 0.9712\n",
      "Epoch 42/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9826 - acc: 0.9847 - val_loss: -0.9755 - val_acc: 0.9722\n",
      "Epoch 43/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9809 - acc: 0.9826 - val_loss: -0.9707 - val_acc: 0.9701\n",
      "Epoch 44/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9836 - acc: 0.9859 - val_loss: -0.9723 - val_acc: 0.9658\n",
      "Epoch 45/100\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.9791 - acc: 0.9802 - val_loss: -0.9777 - val_acc: 0.9754\n",
      "Epoch 46/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9839 - acc: 0.9874 - val_loss: -0.9749 - val_acc: 0.9712\n",
      "Epoch 47/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9863 - acc: 0.9904 - val_loss: -0.9774 - val_acc: 0.9765\n",
      "Epoch 48/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9850 - acc: 0.9850 - val_loss: -0.9775 - val_acc: 0.9765\n",
      "Epoch 49/100\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.9851 - acc: 0.9874 - val_loss: -0.9741 - val_acc: 0.9722\n",
      "Epoch 50/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9841 - acc: 0.9859 - val_loss: -0.9768 - val_acc: 0.9776\n",
      "Epoch 51/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9863 - acc: 0.9886 - val_loss: -0.9776 - val_acc: 0.9776\n",
      "Epoch 52/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9877 - acc: 0.9895 - val_loss: -0.9809 - val_acc: 0.9797\n",
      "Epoch 53/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9864 - acc: 0.9883 - val_loss: -0.9750 - val_acc: 0.9733\n",
      "Epoch 54/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9886 - acc: 0.9910 - val_loss: -0.9772 - val_acc: 0.9744\n",
      "Epoch 55/100\n",
      "3329/3329 [==============================] - 0s 126us/step - loss: -0.9879 - acc: 0.9901 - val_loss: -0.9785 - val_acc: 0.9797\n",
      "Epoch 56/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9859 - acc: 0.9880 - val_loss: -0.9777 - val_acc: 0.9765\n",
      "Epoch 57/100\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9860 - acc: 0.9865 - val_loss: -0.9806 - val_acc: 0.9829\n",
      "Epoch 58/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9884 - acc: 0.9895 - val_loss: -0.9753 - val_acc: 0.9744\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9881 - acc: 0.9901 - val_loss: -0.9814 - val_acc: 0.9786\n",
      "Epoch 60/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9897 - acc: 0.9910 - val_loss: -0.9782 - val_acc: 0.9754\n",
      "Epoch 61/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9908 - acc: 0.9931 - val_loss: -0.9809 - val_acc: 0.9786\n",
      "Epoch 62/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9867 - acc: 0.9865 - val_loss: -0.9783 - val_acc: 0.9776\n",
      "Epoch 63/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9878 - acc: 0.9874 - val_loss: -0.9822 - val_acc: 0.9818\n",
      "Epoch 64/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9900 - acc: 0.9916 - val_loss: -0.9811 - val_acc: 0.9786\n",
      "Epoch 65/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9899 - acc: 0.9913 - val_loss: -0.9809 - val_acc: 0.9765\n",
      "Epoch 66/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9930 - acc: 0.9940 - val_loss: -0.9808 - val_acc: 0.9786\n",
      "Epoch 67/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9911 - acc: 0.9913 - val_loss: -0.9714 - val_acc: 0.9701\n",
      "Epoch 68/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9887 - acc: 0.9913 - val_loss: -0.9840 - val_acc: 0.9840\n",
      "Epoch 69/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9904 - acc: 0.9919 - val_loss: -0.9774 - val_acc: 0.9765\n",
      "Epoch 70/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9909 - acc: 0.9913 - val_loss: -0.9701 - val_acc: 0.9658\n",
      "Epoch 71/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9914 - acc: 0.9931 - val_loss: -0.9802 - val_acc: 0.9776\n",
      "Epoch 72/100\n",
      "3329/3329 [==============================] - 0s 127us/step - loss: -0.9921 - acc: 0.9940 - val_loss: -0.9840 - val_acc: 0.9818\n",
      "Epoch 73/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9931 - acc: 0.9952 - val_loss: -0.9838 - val_acc: 0.9808\n",
      "Epoch 74/100\n",
      "3329/3329 [==============================] - 0s 134us/step - loss: -0.9908 - acc: 0.9922 - val_loss: -0.9734 - val_acc: 0.9690\n",
      "Epoch 75/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9892 - acc: 0.9880 - val_loss: -0.9842 - val_acc: 0.9840\n",
      "Epoch 76/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9927 - acc: 0.9934 - val_loss: -0.9782 - val_acc: 0.9765\n",
      "Epoch 77/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9915 - acc: 0.9907 - val_loss: -0.9792 - val_acc: 0.9754\n",
      "Epoch 78/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9913 - acc: 0.9916 - val_loss: -0.9854 - val_acc: 0.9872\n",
      "Epoch 79/100\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9930 - acc: 0.9940 - val_loss: -0.9822 - val_acc: 0.9808\n",
      "Epoch 80/100\n",
      "3329/3329 [==============================] - 0s 137us/step - loss: -0.9939 - acc: 0.9946 - val_loss: -0.9839 - val_acc: 0.9840\n",
      "Epoch 81/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9948 - acc: 0.9967 - val_loss: -0.9825 - val_acc: 0.9808\n",
      "Epoch 82/100\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.9949 - acc: 0.9967 - val_loss: -0.9821 - val_acc: 0.9786\n",
      "Epoch 83/100\n",
      "3329/3329 [==============================] - 0s 140us/step - loss: -0.9939 - acc: 0.9943 - val_loss: -0.9850 - val_acc: 0.9840\n",
      "Epoch 84/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9947 - acc: 0.9952 - val_loss: -0.9849 - val_acc: 0.9829\n",
      "Epoch 85/100\n",
      "3329/3329 [==============================] - 0s 139us/step - loss: -0.9893 - acc: 0.9904 - val_loss: -0.9824 - val_acc: 0.9818\n",
      "Epoch 86/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9938 - acc: 0.9955 - val_loss: -0.9851 - val_acc: 0.9840\n",
      "Epoch 87/100\n",
      "3329/3329 [==============================] - 0s 135us/step - loss: -0.9949 - acc: 0.9943 - val_loss: -0.9828 - val_acc: 0.9808\n",
      "Epoch 88/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9957 - acc: 0.9964 - val_loss: -0.9839 - val_acc: 0.9829\n",
      "Epoch 89/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9963 - acc: 0.9964 - val_loss: -0.9856 - val_acc: 0.9850\n",
      "Epoch 90/100\n",
      "3329/3329 [==============================] - 0s 138us/step - loss: -0.9966 - acc: 0.9979 - val_loss: -0.9841 - val_acc: 0.9829\n",
      "Epoch 91/100\n",
      "3329/3329 [==============================] - 0s 130us/step - loss: -0.9954 - acc: 0.9961 - val_loss: -0.9829 - val_acc: 0.9797\n",
      "Epoch 92/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9964 - acc: 0.9976 - val_loss: -0.9847 - val_acc: 0.9840\n",
      "Epoch 93/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9963 - acc: 0.9979 - val_loss: -0.9797 - val_acc: 0.9765\n",
      "Epoch 94/100\n",
      "3329/3329 [==============================] - 0s 132us/step - loss: -0.9934 - acc: 0.9937 - val_loss: -0.9855 - val_acc: 0.9840\n",
      "Epoch 95/100\n",
      "3329/3329 [==============================] - 0s 128us/step - loss: -0.9970 - acc: 0.9988 - val_loss: -0.9868 - val_acc: 0.9829\n",
      "Epoch 96/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9957 - acc: 0.9964 - val_loss: -0.9854 - val_acc: 0.9840\n",
      "Epoch 97/100\n",
      "3329/3329 [==============================] - 0s 131us/step - loss: -0.9969 - acc: 0.9973 - val_loss: -0.9833 - val_acc: 0.9808\n",
      "Epoch 98/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9982 - acc: 0.9994 - val_loss: -0.9855 - val_acc: 0.9829\n",
      "Epoch 99/100\n",
      "3329/3329 [==============================] - 0s 133us/step - loss: -0.9947 - acc: 0.9946 - val_loss: -0.9840 - val_acc: 0.9829\n",
      "Epoch 100/100\n",
      "3329/3329 [==============================] - 0s 136us/step - loss: -0.9958 - acc: 0.9970 - val_loss: -0.9855 - val_acc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions, from the data\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_val = X_val.reshape(X_val.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#Create array to store performance metrics\n",
    "param_perf = []\n",
    "\n",
    "# Tuning hyperparameters\n",
    "start_time = time.time()\n",
    "model = Sequential()\n",
    "# First convolutional layer, note the specification of shape\n",
    "model.add(Conv2D(32, kernel_size=(1, 1),\n",
    "                    activation='relu',\n",
    "                    input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.cosine_proximity,\n",
    "                optimizer=keras.optimizers.Adamax(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "cnn_hist = model.fit(X_train, y_train,\n",
    "            batch_size=64,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa38512aa20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAFNCAYAAACUvLFdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzIrxHyI9ywmRSuXTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = cnn_hist.history['acc']\n",
    "val_acc = cnn_hist.history['val_acc']\n",
    "\n",
    "plt.figure(1, figsize=(7,5))\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.title('train_acc vs val_acc vs test_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'val', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
